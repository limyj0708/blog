[
  {
    "objectID": "posts/2019-10-12-Map vs List Comprehension.html",
    "href": "posts/2019-10-12-Map vs List Comprehension.html",
    "title": "limyj_code_archive",
    "section": "",
    "text": "List comprehension vs Map\n위의 Stack Overflow 질문에 아주 좋은 답변들이 달려 있어서, Upvote 상위 두 개 답변을 살펴보았다.\n\n\n\nMap이 몇몇 경우에 아주 약간 더 빠르다. (lambda 안 쓰고, 같은 기능을 하는 함수를 사용할 경우) List Comprehension은 나머지 경우에서 더 빠르며, 대부분의 파이썬 사용자들은 List Comprehension이 더 직관적이고 명확하다고 생각한다.\n# 터미널에서 아래와 같이 실행해보자\n\n$ python -mtimeit -s'xs=range(10)' 'map(hex, xs)'\n100000 loops, best of 3: 4.86 usec per loop\n# hex() -> 16진수로 변경\n\n$ python -mtimeit -s'xs=range(10)' '[hex(x) for x in xs]'\n100000 loops, best of 3: 5.58 usec per loop\n# 그냥 함수를 사용했더니, map이 근소하게 더 빠르다\n하지만 lambda를 쓰면 어떨까?\n$ python -mtimeit -s'xs=range(10)' 'map(lambda x: x+2, xs)'\n100000 loops, best of 3: 4.24 usec per loop\n$ python -mtimeit -s'xs=range(10)' '[x+2 for x in xs]'\n100000 loops, best of 3: 2.32 usec per loop\n\n# 속도가 정 반대가 되었다.\n\n\n\nLaziness\nPython에서 Map은 게으르다. 무슨 말인고 하니, 계산 결과 전체를 반환하는 것이 아니라, 계산 로직을 보관하고 있다가 값 요청이 왔을 때 계산하여 값을 제공해준다는 것이다.\n>>> map(str, range(10**100))\n<map object at 0x2201d50>\n# 리스트가 아니다\nList Comprehension이라면 전체 계산결과 리스트를 반환한다. (Not lazy)\n>>> [str(n) for n in range(10**100)]\n# 이런 짓 하지 말라는 것이다.\n# DO NOT TRY THIS AT HOME OR YOU WILL BE SAD #\n‘게으른’ List Comprehension도 Generator expression의 형태로 지원한다.\n>>> (str(n) for n in range(10**100))\n<generator object <genexpr> at 0xacbdef>"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "limyj_code_archive",
    "section": "",
    "text": "Linux\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nlimyj0708\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2021-09-07-Crontab으로 Python 스크립트 주기적으로 실행하기.html",
    "href": "posts/2021-09-07-Crontab으로 Python 스크립트 주기적으로 실행하기.html",
    "title": "Crontab으로 Python 스크립트 주기적으로 실행하기",
    "section": "",
    "text": "sudo crontab -e : crontab 설정 오픈. 자동으로 root가 작업하는 것으로 인지됨\n설정\n\n경로는 절대경로를 입력해야 제대로 작동\n\nPython 경로도 절대경로로 입력해 줘야 함\n\n시간설정은 아래 링크에서 직관적으로 확인 가능\n\nCrontab.guru - The cron schedule expression editor\n\n\n\n30 8 * * * /usr/local/bin/python3.9 /home/limyj0708/cw_daily_bigquery/cw_daily.py\n\ncron 재시작\n\n재시작해야 적용됨\nservice cron restart\nCentOS일 경우, service crond restart"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html",
    "href": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html",
    "title": " Mac에 Oracle DB 설치하기로 Docker 시작하기",
    "section": "",
    "text": "새로운 도구의 필요성은 언제나 갑자기 찾아온다. “오너라, 오라클! 난 Docker 마스터다! 널 맥에 바로 설치해주마!” 같은 상황은 살면서 별로 일어나지 않는다.\n그렇다고 구글링을 해서 나온 명령어들을 그저 복사&붙여넣기 하여 설치하기만 하면, 응용도 안 되고 단지 시간을 쓴 것에 지나지 않게 된다.\n단순한 따라하기를 넘어서, Docker로 Oracle DB를 Mac에 설치하는 과정을 통해 Docker의 개념과 기본 명령어들을 공부해보자. Docker Desktop for mac"
  },
  {
    "objectID": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#docker가-뭐요",
    "href": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#docker가-뭐요",
    "title": " Mac에 Oracle DB 설치하기로 Docker 시작하기",
    "section": "1. Docker가 뭐요?",
    "text": "1. Docker가 뭐요?\n일단 Nomad Coders의 영상을 본 다음에, 좋은 소개 자료들을 읽어보자. * Docker 공식 문서 / Docker Overview * Docker 공식 문서 / Container 개념 소개 페이지 * 초보를 위한 도커 안내서 - 도커란 무엇인가?\nDocker Overview 페이지와 Wikipedia의 설명을 요약하면, 아래와 같이 정리할 수 있지 않을까?\n’Container’라 불리는 단위로 어플리케이션을 묶고, 인프라로부터 분리하여, 인프라에 종속되지 않는 어플리케이션 실행과 빠른 배포를 가능하게 하는 플랫폼"
  },
  {
    "objectID": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#docker의-구조",
    "href": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#docker의-구조",
    "title": " Mac에 Oracle DB 설치하기로 Docker 시작하기",
    "section": "2. Docker의 구조",
    "text": "2. Docker의 구조\n\n2-1. Docker Engine\n다음은 Docker Engine의 구조이다. 서버-클라이언트 형식으로 되어 있다.이 Docker Engine 위에서 Container가 돌아가고, 이런저런 관리를 하게 된다.\n\n\n\n\n\nOops, Some network ants ate this pic!\n\n\n\nDaemon 프로세스인 서버가 돌아가고 있다.\nREST API : 프로그램들이 deamon과 통신하고 뭘 해야 할 지 명령할 때, 사용할 수 있는 인터페이스를 명시하는 REST API.\nCLI Client : AWS CLI 처럼 HTTP API WRAPPER로서 기능함. 아래 설명을 잘 읽어 보자. > When you use docker run command to start up a Container, your docker client will translate that command into http API call, sends it to docker daemon, Docker daemon then evaluates the request, talks to underlying os and provisions your Container.\n\n\n\n2-2. Docker Architecture\n\n\n\n\n\nOops, Some network ants ate this pic!\n\n\n\n\nClient가 Daemon에게 요청을 보낸다.\n\nClient와 Daemon은 같은 시스템에서 작동할 수도 있고,\nClient가 별도 서버의 Daemon에 접속할 수도 있다.\n\nClient와 Daemon은 UNIX Socket(로컬에서 돌아갈 때)이나 네트워크 인터페이스를 통해, REST API로 통신한다.\n\n\nThe Docker daemon\n\nDocker daemon(dockerd)는 Docker API의 요청을 받아서, Docker Object(image, Container, network, volume…)들을 관리한다.\nDocker service들을 관리하기 위해 다른 daemon들과 통신할 수도 있음.\n\n\n\nThe Docker client\n\nDocker client(docker) : Docker와 상호작용 하기 위한 가장 주요한 방법! e.g : docker run명령어를 실행하면, client는 dockerd에 이 명령어를 보낸다. docker명령은 Docker API를 사용한다.\n여러 개의 daemon과 통신할 수도 있다.\n\n\n\nDocker registries\n\nDocker image들의 저장장소. Docker Hub라는 Public registy가 제공된다. (image를 찾을 때, 찾는 장소는 Docker Hub가 기본값이다!) Private registry도 사용 가능."
  },
  {
    "objectID": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#docker-objects-container-image",
    "href": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#docker-objects-container-image",
    "title": " Mac에 Oracle DB 설치하기로 Docker 시작하기",
    "section": "3. Docker objects : Container? image?",
    "text": "3. Docker objects : Container? image?\n\n3-1. Image\n\nImage는 Container를 만들기 위한 명령들이 들어 있는 읽기 전용 템플릿이다.\nImage를 만들기 위해서는 Dockerfile을 만들어야 한다.\n\nDockerfile은 image를 만들고 실행하는데 필요한 단계들을 정의하는 구문들을 담고 있는 파일이다.\nDockerfile의 각 명령들은 image의 각 layer들을 생성한다. Dockerfile을 수정하고 다시 빌드하면, 바꾼 layer만 변경된다. 그래서 다른 가상화 기술에 비해 가볍고 작고 빠르다.\n\nImage는 상태(state)를 가지지 않으며, 변하지 않는다.(Container의 설계도가 상황에 따라 이리저리 변하면 곤란할 것이다.)\nLayer로 구성된 특성 덕분에, 특정 이미지를 약간 수정한 다른 이미지를 쉽게 만들 수 있다.\n\ne.g. Ubuntu 이미지를 기반으로, Ubuntu에 Node.js를 설치한 다른 이미지 생성.\n\n\n위의 설명을 시각화하면 아래처럼 된다. \n\n\n3-2. Container (is a runnable instance of image)\n\n제목에 써 있는 대로, image의 인스턴스. image가 실행된 상태.\nDocker 공식 Container 소개 페이지에 따르면, 아래와 같은 컨셉으로 작동한다. VM은 비교를 위해 언급되어 있다.\n\n\n\n\n\n\nOops, Some network ants ate this pic!\n\n\n\nContainers Containers are an abstraction at the app layer that packages code and dependencies together. Multiple Containers can run on the same machine and share the OS kernel with other Containers, each running as isolated processes in user space. Containers take up less space than VMs (Container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems.\n\n\nVIRTUAL MACHINES Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers. The hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries and libraries - taking up tens of GBs. VMs can also be slow to boot.\n\nContainer의 특징들 * Docker API, CLI로 만들고(create) 시작하고(start) 멈추고(stop) 옮기고(move) 할 수 있다. * 하나 혹은 여러 네트워크에 연결하고, 저장소를 추가하고, Container의 현재 상태를 기반으로 새 image도 만들 수 있다. * 기본적으로는, Container는 다른 Container, 자신의 Host와 잘 분리되어 있으며, 이 격리 상태도 조정할 수 있다. * Container는 (image) + (생성, 실행 시 받는 구성 옵션 값)에 의해 정의된다.(configuration option) * Container가 삭제될 때에는, 영구 저장소에 저장되지 않은 상태 변경 값은 사라진다. 그렇다. 모든 변경 사항은 Container의 R/W Layer에 저장되며, 이 Layer는 Container가 삭제되면 같이 사라진다.\ndocker run 명령어 예시로 알아보는 Container 생성과정 % docker run -i -t ubuntu /bin/bash 위의 명령어를 실행하면, ubuntu Container를 만들고 실행해서 로컬 command-line 세션에 붙이고, Ubuntu의 Bash Shell을 실행한다. 어떤 일이 일어나는걸까? 1. ubuntu image가 로컬에 없으면, Docker가 image를 내가 설정해 둔 registry에서 pull한다. docker pull ubuntu를 직접 입력한 것처럼. (기본 registry는 Docker Hub) 1. Docker가 새 Container를 만든다. docker Container create를 직접 입력한 것처럼. 1. Docker가 읽고 쓰기가 가능한 파일시스템을 Container의 최종 레이어로써 할당한다.(R/W Layer) 이는 Container가 로컬 파일시스템에서 파일과 디렉토리를 만들고 수정할 수 있게 해 준다. 1. 네트워크 옵션을 하나도 주지 않았기 때문에, Docker가 Container를 기본 네트워크에 연결하기 위해 네트워크 인터페이스를 만든다. 이 과정은 IP 주소를 Container에 할당하는 과정이 포함된다. 자연스럽게, Container는 host의 네트워크 연결을 사용하여 외부 네트워크에 접속할 수 있게 된다. 1. Docker가 Container를 켠 후 /bin/bash를 실행한다. Container는 상호작용이 가능하게(interactively) 동작하고 있고, 터미널에 붙어 있기 때문에 (-i,-t 플래그를 넣어서), 키보드로 명령을 입력할 수 있고, 출력을 터미널로 받아볼 수 있다. 1. /bin/bash명령을 끄기 위해 exit를 입력하면, Container는 멈추지만 제거되지는 않는다. 다시 시작하거나 제거할 수 있다.\n\n\n3-3. Services\n(이 내용은 당장 활용할 일이 없다. 이후 사용의 필요가 느껴지면 심도있게 알아보자.) (Swarm에 대해 소개하는 아주 좋은 글) Service는 여러 개의 Docker daemon위에서 Container를 스케일링 할 수 있게 해준다. 이 여러 개의 Docker daemon들은 Swarm이라는, 여러 개의 manager, worker를 가지고 있는 단위로 뭉쳐서 작동한다. Swarm의 각 멤버들은 Docker daemon이고, daemon들은 Docker API를 사용하여 통신한다. Service는 원하는 상태를 정의할 수 있게 해 주는데, 특정 시간에 반드시 접근 가능해야 하는 Service 복제체의 숫자라던가 하는 것이다. 기본적으로, Service는 모든 worker node들에 부하 분산처리된다.(load-balanced) 사용자에게는 Docker service가 하나의 어플리케이션으로 보인다. Docker 1.12버전 이상부터 지원됨!"
  },
  {
    "objectID": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#여기까지-읽었을-때의-궁금한-점들",
    "href": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#여기까지-읽었을-때의-궁금한-점들",
    "title": " Mac에 Oracle DB 설치하기로 Docker 시작하기",
    "section": "4. 여기까지 읽었을 때의 궁금한 점들",
    "text": "4. 여기까지 읽었을 때의 궁금한 점들\n\n4-1. Daemon이 뭐지?\n\nhttps://en.wikipedia.org/wiki/Daemon_(computing) In multitasking computer operating systems, a daemon (/ˈdiːmən/ or /ˈdeɪmən/)[1] is a computer program that runs as a background process, rather than being under the direct control of an interactive user. 악마는 당신의 등 뒤에서 조용히 돌아가고 있다… :) \n\n\n\n4-2. Rest API가 뭐지?\nREpresentational State Transfer 이 영상 이상으로 잘 설명한 자료가 있을까?내용이 방대하기 때문에, 추후 별도의 정리를 진행해야겠다.  > youtube: https://www.youtube.com/watch?v=RP_f5dMoHFc \n\n\n4-3. Socket이 뭐지?\n프로세스 간 데이터 교환을 위한, 소프트웨어로 작성된 통신 접속점 아래는 Unix Socket(Unix Domain Socket)과 IP Socket에 대한 설명이다. > https://serverfault.com/questions/124517/whats-the-difference-between-unix-socket-and-tcp-ip-socket > A UNIX socket is an inter-process communication mechanism that allows bidirectional data exchange between processes running on the same machine. > IP sockets (especially TCP/IP sockets) are a mechanism allowing communication between processes over the network. In some cases, you can use TCP/IP sockets to talk with processes running on the same computer (by using the loopback interface). > UNIX domain sockets know that they’re executing on the same system, so they can avoid some checks and operations (like routing); which makes them faster and lighter than IP sockets. So if you plan to communicate with processes on the same host, this is a better option than IP sockets.\n아래 글들도 읽어보도록 하자. * 소켓과 포트 * 소켓 프로그래밍 * 소켓 프로그래밍 기초 * 번외 : 서버,클라이언트,호스트"
  },
  {
    "objectID": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#그래서-선생-이-명령어가-도대체-뭐요",
    "href": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#그래서-선생-이-명령어가-도대체-뭐요",
    "title": " Mac에 Oracle DB 설치하기로 Docker 시작하기",
    "section": "5. 그래서 선생, 이 명령어가 도대체 뭐요?",
    "text": "5. 그래서 선생, 이 명령어가 도대체 뭐요?\n\n5-1. 어떤 명령어들을 사용하였는가\nOracle DB 설치와 실행을 위해 어떤 명령어들을 사용하였는가? (클릭하면 각 명령어 설명 공식문서로 이동함)\n\ndocker search oracle : 기본 registry인 docker hub에서, oracle이라는 단어를 포함한 image를 찾는다. 추천수 순으로 정렬되어 나온다. 그런데 솔직히 Docker Hub에서 검색하는 것이 더 좋다.\ndocker pull oracleinanutshell/oracle-xe-11g : registry에서 image나 repository를 가져온다. 여기서는 추천수가 가장 높았던 oracleinanutshell/oracle-xe-11g 라는 image를 가져왔다. Docker Hub : oracleinanutshell/oracle-xe-11g 설명을 보니 Ubuntu 18.04 LTS에 Oracle xe 11g를 올린 image다.\ndocker run --name oracle-xe-11g -d -p 8080:8080 -p 1521:1521 oracleinanutshell/oracle-xe-11g : docker run [OPTIONS] image [COMMAND] [ARG...] 이런 구조로 되어있다. Container를 생성하여 실행한다. 여기서 사용한 옵션값부터 살펴보자.\n\n--name : Container의 이름을 설정한다. 중복 이름은 허용하지 않음.\n-d : Container를 백그라운드에서 실행하고, Container ID를 출력한다. Background와 Foreground의 차이\n-p : 특정 범위의 포트, 혹은 포트 하나를 host에 publish한다. 여기서는 hostPort:ContainerPort 구조로 사용했다. 즉, Container의 8080포트를 Host의 8080포트에 매핑하는 방화벽 규칙을 만든다. (하필이면 8080, 1521인 이유는, Oracle Listener가 사용하는 포트가 1521이고, XML DB가 8080포트를 사용하기 때문이다.) docker port oracle-xe-11g로 연결된 포트를 확인해보면, 다음과 같이 뜬다.\n\n1521/tcp -> 0.0.0.0:1521\n8080/tcp -> 0.0.0.0:8080\n포트들이 0.0.0.0 (all IPv4 addresses on the local machine)의 동일 포트에 매핑되었다. 이제 Container가 생성된 후 실행되었는데, 그럼 다음엔 뭘 해야 할까? * 참고 공식 문서 : Container networking * 참고 공식 문서 : Docker run reference\ndocker exec -it oracle-xe-11g bash : 외부에서, 실행 중인 Container 안의 명령을 실행한다. oracle-xe-11g Container는 Ubuntu 18.04위에서 Oracle DB를 구동하는 구조이기 때문에, bash shell을 열라는 명령어를 보내 보았다.(bash) 옵션 -it는 뭘까?\n\n-i : 키보드, 화면을 통해 STDIN, STDOUT(표준입력, 표준출력)[설명][설명의 번역]을 열고 유지한다. 명령어 입력, 결과 출력을 위해서 넣어주어야 하는 값이다.\n-t : pseudo-TTY를 할당한다. 터미널 환경을 에뮬레이션 해 주는데, 이 옵션을 입력하지 않으면 터미널 환경이 보이지 않는다.(i와 t값을 넣지 않으면 각각 어떻게 되는가? 는 이 블로그를 참고하자.) 보기만 해서는 잘 기억나지 않을테니, 직접 해보자.\n\n% docker exec oracle-xe-11g bash\n%\n하나도 안 쓰면 바로 종료된다. 입출력도, tty도 활성화되지 않았으니 당연한 결과. % docker exec -t oracle-xe-11g bash   root@a702ae5d7f10:/# sqlplus -t만 쓰면, 첫 번째 명령어 입력까지는 가능하나 그 후의 결과가 출력되지 않는다. STDIN을 열지 않았으니 당연한 결과. % docker exec -i oracle-xe-11g bash   sqlplus   bash: line 1: sqlplus: command not found   ls   bin   boot   dev   ...(이하생략) -i만 쓰면, 터미널 환경이 조성되지 않는다. 그냥 명령어를 입력하면 sqlplus는 command not found 에러가 뜨고, ls는 제대로 출력이 되긴 한다. 응용 프로그램(sqlplus) 실행은 안 되고, 기본 shell command는 제대로 실행되는 건 terminal의 부재 때문이 아닌가 추측해본다. 자세한 이유는 다음에 알아보기로 하자. ``` % docker exec -it oracle-xe-11g bash\nroot@a702ae5d7f10:/# sqlplus\nSQL*Plus: Release 11.2.0.2.0 Production on Sun Oct 27 02:33:24 2019\nCopyright (c) 1982, 2011, Oracle. All rights reserved.\nEnter user-name: system Enter password:\nConnected to: Oracle Database 11g Express Edition Release 11.2.0.2.0 - 64bit Production\nSQL> ``` 제대로 모두 입력하여 sqlplus에 로그인까지 진행하면 이렇게 된다.\n\n도대체 pseudo-TTY가 뭐지? 에 대한 글은 다음 링크를 참고하자. * Bash Shell에 대한 엄청난 gitbook : TTY * 콘솔? 터미널? 쉘?\n- oracleinanutshell/oracle-xe-11g image로부터 Container를 실행하였고, Container에서 sqlplus를 실행해서 로그인도 해 봤다. - 설정을 다 했다. 그런데 컴퓨터 재부팅을 하거나, Docker를 종료했다가 Container를 또 실행하고 싶으면 어떻게 해야 할까?\n-docker start oracle-xe-11g : 하나, 혹은 여러 개의 멈춘 Container를 실행한다. 여기서는 docker run으로 생성한 ‘oracle-xe-11g’ 라는 이름을 붙인 Container를 실행한다.\n\n\n5-2. 뭐 하나 잊어버린 것 같은데..? : Volume\n그런데 여기서 빼먹은 것이 하나 있다. 위에 위험한 설명이 하나 있었던 것 같은데? > Container가 삭제될 때에는, 영구 저장소에 저장되지 않은 상태 변경 값은 사라진다. 그렇다. 모든 변경 사항은 Container의 R/W Layer에 저장되며, 이 Layer는 Container가 삭제되면 같이 사라진다.\nContainer를 영영 없애지 않을 생각이거나, 한 Container의 데이터를 다른 Container와 공유하지 않을 생각이라면 지금까지 입력한 명령어들만으로도 충분하다. 하지만 아니라면? Volume을 사용, 데이터를 Host에 저장하여 안전하게 유지, 공유해보자. 아래 두 링크를 꼭 읽어보자. 초반 부분만 읽어봐도 된다. * Docker 공식 페이지 / Use volumes * Docker 공식 페이지 / About storage drivers\n\nVolumes are the preferred mechanism for persisting data generated by and used by Docker Containers.\n\n\nThe major difference between a Container and an image is the top writable layer. All writes to the Container that add new or modify existing data are stored in this writable layer. When the Container is deleted, the writable layer is also deleted. The underlying image remains unchanged. Because each Container has its own writable Container layer, and all changes are stored in this Container layer, multiple Containers can share access to the same underlying image and yet have their own data state.\n\n그럼, oracle-xe-11g Container 안의 어떤 폴더를 Host의 폴더와 연결해 주어야 할까? Container 안에서 oracle이란 이름을 가진 폴더를 검색해보자.\n$ find / -name oracle -type d  # 전체 폴더에서 oracle 이름을 가진 폴더 검색\n/u01/app/oracle\n오호라, /u01/app/oracle를 연결하면 될 것 같다.\ndocker run문서에 따르면, Volume을 할당하기 위해 다음과 같은 옵션이 필요하다. -v [Host directory]:[Container directory] 이 옵션을 추가하여, Container를 다시 생성해 보자.\ndocker run --name oracle-xe-11g -d -p 8080:8080 -p 1521:1521 -v /Users/youngjinlim/Coding/BigData_Study/SQL/Docker_volume:/u01/app/oracle oracleinanutshell/oracle-xe-11g\n과연 Volume이 잘 Mount 되었을까?\n% docker inspect --format='{{.Mounts}}' oracle-xe-11g\n[{bind  /Users/youngjinlim/Coding/BigData_Study/SQL/Docker_volume /u01/app/oracle   true rprivate}]\n오, 잘 연결된 것 같다. 그런데… DB에 연결할 수가 없었다! 왜지?\nroot@141d12eb18ac:/u01/app/oracle# ls -l\ntotal 0\n어엉? Container 쪽 폴더가 텅 비어버렸다! 아무래도 Host쪽의 폴더로 덮어씌워진 것 같다. 아.. 너무 고통스럽다.. 이에 대한 원인과 해결방법은 이 블로그에서 찾을 수 있었다. * docker volume의 사용방법과 차이점 : !!주의!! 이 블로그 포스팅에선 docker create volume volume_name 라고 썼는데, 이러면 안된다. 왜냐면..\n\nhttps://docs.docker.com/engine/reference/commandline/create/ Description : Create a new Container Usage : docker create [OPTIONS] image [COMMAND] [ARG…] docker create는 Container를 만들 때 쓰는 명령어이기 때문이다. docker volume을 써야 한다.\n\nHost쪽 폴더가 텅 비어있을 때, Container쪽 폴더를 남기려면 아래와 같은 방법을 사용해야 한다.\ndocker volume create volume_name\ndocker run --name oracle-xe-11g -d -v volume_name:/Container/some/where ...(이하생략)\n그럼 실행해 보자.\n% docker volume create oracle-xe-11g_study    # Volume 생성\n% docker volume ls    # 잘 생성되었는지 확인\nDRIVER              VOLUME NAME\nlocal               oracle-xe-11g_study\n% docker run --name oracle-xe-11g_study -d -v oracle-xe-11g_study:/u01/app/oracle -p 8080:8080 -p 1521:1521 oracleinanutshell/oracle-xe-11g\n6a7d5728c9084c9f2c25931a8a7bf1120594776380d5cd8e17d6d15b48604eb6    # 새 Container 생성\n% docker exec -it oracle-xe-11g_study bash    # /u01/app/oracle 폴더 무사한지 확인하러 들어감\nroot@6a7d5728c908:/# cd /u01/app/oracle\nroot@6a7d5728c908:/u01/app/oracle# ls -l    # 결과를 보면 무사함을 알 수 있음\ntotal 24\ndrwxr-x--- 4 oracle dba  4096 Oct 27 03:39 admin\ndrwxrwxr-x 4 oracle dba  4096 Oct 27 03:39 diag\ndrwxr-x--- 3 oracle dba  4096 Oct 27 03:39 fast_recovery_area\ndrwxr-x--- 3 oracle dba  4096 Oct 27 03:39 oradata\ndrwxr-xr-x 3 oracle dba  4096 Oct 27 03:39 oradiag_oracle\ndrwxr-xr-x 3 root   root 4096 Oct 27 03:39 product\nroot@6a7d5728c908:/u01/app/oracle# exit\nexit\n% docker inspect --format='{{.Mounts}}' oracle-xe-11g_study    # Volume 잘 연결 되었는지 확인\n[{volume oracle-xe-11g_study /var/lib/docker/volumes/oracle-xe-11g_study/_data /u01/app/oracle local z true }]\n연결도 잘 됐고, Container 쪽 폴더도 무사하다. ‘CUSTOMERS’ 라는 이름의 테이블을 추가한 후, Container를 새로 생성해서 같은 Volume에 연결했을 경우, 새로 생성한 Container에서도 CUSTOMERS 테이블이 잘 보이는지 확인해 보자.\n\n\n\n\n\nOops, Some network ants ate this pic!\n\n\n% docker run --name oracle-xe-11g_volumetest -d -v oracle-xe-11g_study:/u01/app/oracle -p 8080:8080 -p 1521:1521 oracleinanutshell/oracle-xe-11g\n08ba1459d196d6094b7adc2232d843e430574551cb1ba4c823fae7f85aa8fe36\nyoungjinlim@Youngui-MacBookPro ~ % docker ps\n...중략  NAMES\n        oracle-xe-11g_volumetest\n새로 생성한 Container 하나만 실행 중이다.(oracle-xe-11g_volumetest) 이제 추가했던 테이블이 그대로 있는지 확인해 보자.\n\n\n\n\n\nOops, Some network ants ate this pic!\n\n\n잘 있다.\n일단 Mac에서 Oracle DB를 사용하기 위한 여정은 여기서 끝이다."
  },
  {
    "objectID": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#이번에-알아본-것",
    "href": "posts/2019-10-18-lets-start-docker-through-installing-oracle11g-on-mac.html#이번에-알아본-것",
    "title": " Mac에 Oracle DB 설치하기로 Docker 시작하기",
    "section": "이번에 알아본 것",
    "text": "이번에 알아본 것\n\nDocker의 기본적인 개념\nDocker를 개념을 알아보다가 궁금해진 것들\n\n궁금해진 것들 중 너무 큰 주제들이 많았는데, 별도로 정리를 할 필요가 있어 보인다.\n\nOracle Database 11g 설치 중 사용한 명령어들의 의미\n\nDocker 공식문서가 최고다. 공식문서를 보시오"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html",
    "href": "posts/2021-11-05-pandas_cheatsheet.html",
    "title": "limyj_code_archive",
    "section": "",
    "text": "” 안 쓰면 잊어버리는, pandas에서의 주요 Dataframe 조작 방법들을 정리”\n\n\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display_html \n\n\n\n\n\n\ndata = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\npd.DataFrame.from_dict(data)\n# key가 컬럼, value로 들어간 리스트가 컬럼의 row 하나하나가 된다.\n\n\n\n\n\n  \n    \n      \n      col_1\n      col_2\n    \n  \n  \n    \n      0\n      3\n      a\n    \n    \n      1\n      2\n      b\n    \n    \n      2\n      1\n      c\n    \n    \n      3\n      0\n      d\n    \n  \n\n\n\n\n\ndict_list = [\n    { \"id\" : 1001001, \"address\" : \"AABCC\"}\n    ,{ \"id\" : 2101001, \"address\" : \"BBBDD\"}\n    ,{ \"id\" : 3201001, \"address\" : \"백두산\"}\n    ,{ \"id\" : 4301001, \"address\" : \"한라산\"}\n    ,{ \"id\" : 5401001, \"address\" : \"몰디브\"}\n] # 같은 key들을 가진 딕셔너리들이 담긴 리스트\npd.DataFrame.from_dict(dict_list) # 이렇게 넣어도, key들이 컬럼이 되어 데이터프레임이 만들어진다.\n# 실무적으로는 이 형태를 더 많이 쓰게 된다.\n\n\n\n\n\n  \n    \n      \n      id\n      address\n    \n  \n  \n    \n      0\n      1001001\n      AABCC\n    \n    \n      1\n      2101001\n      BBBDD\n    \n    \n      2\n      3201001\n      백두산\n    \n    \n      3\n      4301001\n      한라산\n    \n    \n      4\n      5401001\n      몰디브\n    \n  \n\n\n\n\n\n\n\n\ndf = pd.DataFrame(columns=['A','B','BB','C','D'])\n# 컬럼들이 될 리스트를 columns parameter에 argument로 넘김\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n  \n\n\n\n\n\ndf['A'] = [1,3,1]\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      3\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ndf['B'] = [4,4,6]\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[((df['A'] == 1) & (df['B'] == 4)), 'C'] = 444\ndf\n# 컬럼 값 조건을 걸고 값을 변경\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      444\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[(df['B'] == 4), 'C'] = 0\ndf\n# 컬럼 값 조건을 걸고 값을 변경 2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\nsample_list = [1,2,3,4,5]\n# 해당 데이터프레임 가장 아래에 리스트를 row로 넣음\ndf.loc[len(df)] = sample_list\n# 이 방식은 좀 느린 편이며, 데이터프레임에 행을 추가해야 한다면\n# 자료를 dictionary로 관리하다가 모든 데이터 추가가 다 끝나고 데이터프레임으로 변환하는 것이 빠름\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n    \n  \n\n\n\n\n\n\n\n\n\n\n\nprint(type(df.loc[0]))\ndf.loc[0]\n# loc의 첫 번째 인자는 '행 라벨' 이다.\n# 그래서 0을 넣으면, index가 0인 행을 series로 반환하고 있다.\n\n<class 'pandas.core.series.Series'>\n\n\nA       1\nB       4\nBB    NaN\nC       0\nD     NaN\nName: 0, dtype: object\n\n\n\nprint(type(df.loc[0, 'A']))\ndf.loc[0, 'A']\n# 두 번째 인자는 컬럼명이다.\n\n<class 'numpy.int64'>\n\n\n1\n\n\n\ndf.loc[[0,1,2,3], ['A','B']]\n# 이런 식으로 접근하면, 다중 컬럼과 행을 데이터프레임으로 가져올 수 있다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      4\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      1\n      6\n    \n    \n      3\n      1\n      2\n    \n  \n\n\n\n\n\ndf.loc[df.index[0:3], ['A','B']]\n# df.index로도 접근 가능\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      4\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      1\n      6\n    \n  \n\n\n\n\n\ndf.loc[df['B'] == 4]\n# row에 값 조건을 걸 수도 있다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[df['B'] == 4, df.columns.str.contains('B')]\n# 컬럼 이름에도 조건을 걸 수 있다. 위의 경우, 컬럼 이름에 B를 포함하는 컬럼만 가져옴.\n\n\n\n\n\n  \n    \n      \n      B\n      BB\n    \n  \n  \n    \n      0\n      4\n      NaN\n    \n    \n      1\n      4\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[:,df.columns.str.contains('B')]\n# 행 조건 자리에 :를 넣으면, 행에 대해서는 전체를 다 가져오라는 뜻이다.\n\n\n\n\n\n  \n    \n      \n      B\n      BB\n    \n  \n  \n    \n      0\n      4\n      NaN\n    \n    \n      1\n      4\n      NaN\n    \n    \n      2\n      6\n      NaN\n    \n    \n      3\n      2\n      3\n    \n  \n\n\n\n\n\nprint(df.columns) # 컬럼명을 가져옴\nprint(df.columns.str)\nprint(df.columns.str.contains('B')) # boolean indexing이 가능한 형태가 된다.\nprint(type(df.columns.str.contains('B'))) # 결과물은 false와 true가 들어간 ndarray\nprint(df.columns.str.startswith('A')) # 이렇게 하면 A로 시작하는 컬럼을 가져올 수 있음\n# 결론은, 다른 외부 함수를 사용해서 어쩄든 boolean 타입 값이 담긴 리스트를 만들면, loc에 넣어서 boolean indexing이 가능하다는 것.\n\nIndex(['A', 'B', 'BB', 'C', 'D'], dtype='object')\n<pandas.core.strings.StringMethods object at 0x000001E1FEC0B250>\n[False  True  True False False]\n<class 'numpy.ndarray'>\n[ True False False False False]\n\n\n\ndf.loc[:,'new'] = 3\ndf\n# loc으로도 기존에 없던 새 컬럼을 추가할 수 있음\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n    \n  \n\n\n\n\n\ndf.loc[4] = [1] * len(df.columns)\ndf.loc[99] = [1] * len(df.columns)\ndf.loc['cool'] = [22] * len(df.columns)\n# dataframe에 행을 추가함. index가 늘어난다.\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22\n    \n  \n\n\n\n\n\n\n\n\ndf.iloc[0:2,0:4]\n# 기본적 동작은 loc과 동일하나, 받는 인자가 라벨이 아니고 '위치'다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n    \n  \n\n\n\n\n\ndf.iloc[4:7,0:4]\n# 위치를 받기 때문에, index는 99여도 5번째 줄로 인식됨\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n    \n  \n  \n    \n      4\n      1\n      1\n      1\n      1\n    \n    \n      99\n      1\n      1\n      1\n      1\n    \n    \n      cool\n      22\n      22\n      22\n      22\n    \n  \n\n\n\n\n\ndf.iloc[7] = [2] * len(df.columns)\n# IndexError: iloc cannot enlarge its target object\n# 위치를 인자로 받기 때문에, 새로운 컬럼, 행을 만든다거나 하는 행위는 불가능하다.\n\nIndexError: iloc cannot enlarge its target object\n\n\n\n\n\n\ndf.at[1,'A']\n# 한 번에 1개의 스칼라값에만 접근 가능\n# 여러 개의 값에 접근하려고 범위를 지정하면, 에러를 출력한다.\n# 단일 값에 접근하는 목적이라면 loc보다 훨씬 빠름\n\n3\n\n\n\ndf.at[1,'A'] = 100\ndf\n# 값을 딱 하나만 바꾸고 싶다! 라고 하면 at을 활용해보자.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22\n    \n  \n\n\n\n\n\ndf.at[99, 'new']\n# 그 이외에는 label base인 것이 loc과 똑같음\n\n1\n\n\n\n\n\n\ndf.iat[4,2]\n# iloc의 스칼라 버전.\n# 이외의 동작은 at과 같다.\n\n1\n\n\n\ndf.iat[df.index.get_loc('cool'),df.columns.get_loc('new')]\n# get_loc을 쓰면, 해당 인덱스와 컬럼의 위치를 반환받을 수 있음.\n# 그럼 인덱스와 컬럼의 이름으로도 iat, iloc을 이용 가능\n\n22\n\n\n\n\n\n\nmap함수는 DataFrame 타입이 아니라, 반드시 Series 타입에서만 사용해야 한다.\nSeries를 한마디로 정의하면 딱 이거다.\n\n값(value) + 인덱스(index) = 시리즈 클래스(Series)\n\nSeries는 NumPy에서 제공하는 1차원 배열과 비슷하지만 각 데이터의 의미를 표시하는 인덱스(index)를 붙일 수 있다. 하지만 데이터 자체는 그냥 값(value)의 1차원 배열이다.\nmap함수는 Series의 이러한 값 하나하나에 접근하면서 해당 함수를 수행한다.\n\n\nimport math as m # sqrt 함수 사용을 위해 부름\n# http://www.leejungmin.org/post/2018/04/21/pandas_apply_and_map/\ndf[\"map_b\"] = df[\"B\"].map(lambda x : m.sqrt(x)) \n# B컬럼의 값 하나하나에 sqrt 함수를 적용한 결과를 map_b 컬럼으로 추가\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n      map_b\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n      2.000000\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      3\n      2.000000\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n      2.449490\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n      1.414214\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22\n      4.690416\n    \n  \n\n\n\n\n\n\n\n\n커스텀 함수를 사용하기 위해 DataFrame에서 복수 개의 컬럼이 필요하다면, apply 함수를 사용해야 한다.\n\n\nimport math as m # sqrt 함수 사용을 위해 부름\n# 두 컬럼의 제곱근의 값을 각각 곱하는 함수\ndef sqrt_multi(x,y):\n    return m.sqrt(x) * m.sqrt(y)\n\n\ndf.loc[:,'new'] = df.apply(lambda x : sqrt_multi(x['A'], x['B']), axis=1) # axis=1 이면 각 열의 원소에 대해 연산 수행\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n      map_b\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\ndf[\"apply_bb_d\"] = df.apply(lambda x : sqrt_multi(x['BB'], x['B']), axis=1) # axis=1 이면 각 열의 원소에 대해 연산 수행\ndf # NaN과의 연산은 NaN이 됨을 참고하자.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n      map_b\n      apply_bb_d\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\n\n\n\nprint(df.columns)\nprint(type(df.columns))\nprint(df.index)\nprint(type(df.index))\nprint(df.columns[2]) # 위치값으로 개별 요소에 접근 가능\nprint(df.index[6])\n\nIndex(['A', 'B', 'BB', 'C', 'D', 'new', 'map_b', 'apply_bb_d'], dtype='object')\n<class 'pandas.core.indexes.base.Index'>\nIndex([0, 1, 2, 3, 4, 99, 'cool'], dtype='object')\n<class 'pandas.core.indexes.base.Index'>\nBB\ncool\n\n\n\ndf.columns = ['가', '나', '다', '라', '마', '바', '사', '아'] \n# df.columns에 직접 컬럼명 리스트를 할당하여 컬럼명 변경 가능\n# 기존 컬럼 수와 같은 길이의 리스트를 넣지 않으면 오류가 발생함\nprint(df.columns)\nprint(type(df.columns))\n\nIndex(['가', '나', '다', '라', '마', '바', '사', '아'], dtype='object')\n<class 'pandas.core.indexes.base.Index'>\n\n\n\ndf.index = [1,2,3,4,5,6,7] \n# df.columns에 직접 컬럼명 리스트를 할당하여 컬럼명 변경 가능\nprint(df.index)\nprint(type(df.index))\n\nInt64Index([1, 2, 3, 4, 5, 6, 7], dtype='int64')\n<class 'pandas.core.indexes.numeric.Int64Index'>\n\n\n\n\n\nDataFrame.set_index(keys, drop=True, append=False, inplace=False)\n\nkeys에는 index로 할당하고자 하는 열의 레이블을 입력한다.\n\nmulti-index를 하고 싶으면, [‘가’, ‘나’] 이렇게 열 레이블 배열을 입력한다.\n\ndrop : index로 할당한 열을 삭제할까요?\nappend : 기존에 존재하던 index를 삭제할까요?\ninplace : 원본 데이터프레임을 변경할까요?\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index('가') # 기본값\n\n\n\n\n\n  \n    \n      \n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      가\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index('가', drop=False) # index로 선택된 열 삭제 안 함\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      가\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      100\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      1\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      1\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      22\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index('가', append=True) # 기존 index 삭제 안 함\n\n\n\n\n\n  \n    \n      \n      \n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      \n      가\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index(['가','나']) # 동시에 여러 열을 index로 설정하기\n\n\n\n\n\n  \n    \n      \n      \n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      가\n      나\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\n\n\nDataFrame.reset_index(drop=False, inplace=False)\n\n기존에 있던 index 대신에, 0부터 시작하여 1씩 늘어나는 정수 index를 추가한다.\ndrop : 기존에 index였던 열을 삭제할까요?\ninplace : 원본 데이터프레임을 변경할까요?\n\n\ndf.reset_index()\n\n\n\n\n\n  \n    \n      \n      index\n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      0\n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      1\n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      2\n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      3\n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      4\n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      5\n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.reset_index(drop=True)\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\n\n\n\n\n특정 조건의 값을 삭제하고 싶은 경우에는, 해당 조건의 반대 조건을 걸어서 반환 결과를 사용하는 식으로 처리한다.\n\n\n\nDataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')\n\n특정 레이블의 행이나 열을 제거한다.\nlabels : 제거할 index, 레이블 하나 혹은 리스트 (list-like)\naxis : 0이면 행, 1이면 컬럼 대상\nindex : labels, axis=0 대신 사용가능\ncolumns : labels, axis=1 대신 사용가능\nlevel : MultiIndex일 경우, 어떤 레벨을 제거할 것인지\ninplace : 원본 변경 할 건가요?\nerrors : ’ignore’로 세팅하면, 에러 출력 안 하고 존재하는 레이블만 제거한다.\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.drop(labels=['가','아'], axis=1)\n\n\n\n\n\n  \n    \n      \n      나\n      다\n      라\n      마\n      바\n      사\n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n    \n    \n      2\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n    \n    \n      3\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n    \n    \n      4\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\ndf.drop(labels=[1,7], axis=0)\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n  \n\n\n\n\n\ndf.drop(columns=['가','아'])\n# df.drop(labels=['가','아'], axis=1)와 같은 결과\n\n\n\n\n\n  \n    \n      \n      나\n      다\n      라\n      마\n      바\n      사\n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n    \n    \n      2\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n    \n    \n      3\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n    \n    \n      4\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\n\n\n\n\n\nNaN인지 각 값에 대해 확인하여 boolean으로 표현\nisnull() 도 완전히 같은 기능을 한다.\n왜 같은 기능을 하는 함수가 두 개나 있는지는 아래 링크를 참조\n\nhttps://datascience.stackexchange.com/questions/37878/difference-between-isna-and-isnull-in-pandas\nThis is because pandas’ DataFrames are based on R’s DataFrames. In R na and null are two separate things. Read this post for more information. However, in python, pandas is built on top of numpy, which has neither na nor null values. Instead numpy has NaN values (which stands for “Not a Number”). Consequently, pandas also uses NaN values.\n\n\n\ndf.isna()\n# 특정 컬럼, 행에 대해서도 사용 가능\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n      True\n    \n    \n      2\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n      True\n    \n    \n      3\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n      True\n    \n    \n      4\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      5\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      6\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      7\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n  \n\n\n\n\n\n\n\nDataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n\naxis\n\n0 혹은 ‘index’ : missing value가 있는 행을 드랍\n1 혹은 ‘columns’ : missing value가 있는 열을 드랍\n\nhow\n\nany : missing value가 하나라도 있으면 드랍\nall : 전체 값이 다 missing value여야 드랍\n\nthresh : 문턱값. 정수를 입력 시, 정상값이 해당 정수 갯수만큼은 있어야 제거 안 함\nsubset : list-like 오브젝트를 넣으면, 해당 index나 컬럼에서만 missing value 체크\ninplace : 원본 변경 할 건가요?\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.dropna() # 기본적으로 행 드랍\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.dropna(axis=1) # 열 드랍\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      바\n      사\n    \n  \n  \n    \n      1\n      1\n      4\n      2.000000\n      2.000000\n    \n    \n      2\n      100\n      4\n      20.000000\n      2.000000\n    \n    \n      3\n      1\n      6\n      2.449490\n      2.449490\n    \n    \n      4\n      1\n      2\n      1.414214\n      1.414214\n    \n    \n      5\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      6\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      7\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\ndf.dropna(thresh=5) # index 3인 행은 정상값이 4개였음\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.dropna(axis=0, subset=['라']) # '라'열만 검사해서 NaN이 있는 행을 제거함\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\n\n\nDataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n\nvalue : NaN을 무엇으로 채울 것인가?\n\nscalar : 0, 1 따위의 값을 넣음\ndict : {“A”: 0, “B”: 1, “C”: 2, “D”: 3}\n\n컬럼 A의 NaN은 0으로, 컬럼 B의 NaN은 1로, 컬럼 C의 NaN은 2로, 컬럼 D의 NaN은 3으로 대체\n\ndataframe : 대체 대상 dataframe와 같은 크기의 dataframe을 준비한 후, value에 dataframe을 넣으면 NaN 값만 넣은 dataframe의 값으로 대체된다. 컬럼명이나 인덱스는 원본 dataframe의 것이 유지된다.\n\nmethod : 어떤 방법으로 채울까? (value와 같이 사용할 수 없음)\n\nbackfill, bfill : NaN의 다음 값으로 NaN 채우기.\nffill, pad : NaN의 직전 값으로 NaN 채우기.\n\naxis\n\n0 혹은 ‘index’\n1 혹은 ‘columns’\n\ninplace : 원본 변경 할 건가요?\nlimit : 위에서부터 NaN 몇 개만 바꿀래? 기본값 None이면 모든 NaN을 바꾸는 것.\n\n\ndf = pd.DataFrame([[np.nan, 2, np.nan, 0],\n                   [3, 4, np.nan, 1],\n                   [np.nan, np.nan, np.nan, 5],\n                   [np.nan, 3, np.nan, 4]],\n                  columns=list(\"ABCD\"))\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      NaN\n      2.0\n      NaN\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n      5\n    \n    \n      3\n      NaN\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\ndf.fillna(value=0) # 0으로 NaN 채우기\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      0.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      0.0\n      1\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      5\n    \n    \n      3\n      0.0\n      3.0\n      0.0\n      4\n    \n  \n\n\n\n\n\ndf.fillna(method='ffill') # NaN의 직전 값으로 NaN 채우기. 'pad'를 써도 마찬가지\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      NaN\n      2.0\n      NaN\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      3.0\n      4.0\n      NaN\n      5\n    \n    \n      3\n      3.0\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\ndf.fillna(method='bfill') # NaN의 다음 값으로 NaN 채우기. 'backfill'을 써도 마찬가지\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      3.0\n      2.0\n      NaN\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      NaN\n      3.0\n      NaN\n      5\n    \n    \n      3\n      NaN\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\nvalues = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\ndf.fillna(value=values) # values에 dictionary를 넣어서 컬럼마다 NaN을 다른 값으로 대체\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      2.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      2.0\n      1\n    \n    \n      2\n      0.0\n      1.0\n      2.0\n      5\n    \n    \n      3\n      0.0\n      3.0\n      2.0\n      4\n    \n  \n\n\n\n\n\ndf.fillna(value=values, limit=1) # limit=1이어서, 최초의 NaN 하나만 대체\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      2.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      NaN\n      1.0\n      NaN\n      5\n    \n    \n      3\n      NaN\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\ndf2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\ndf2 # 4 by 4 영행렬을 만들어 보자\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      E\n    \n  \n  \n    \n      0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      1\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n\n\n\n\ndf.fillna(df2) #원본 df의 컬럼이 유지됨\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      0.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      0.0\n      1\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      5\n    \n    \n      3\n      0.0\n      3.0\n      0.0\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'A'].fillna(df.loc[:,'A'].mean()) # A열의 NaN 값을 A열의 평균으로 채움\n\n0    3.0\n1    3.0\n2    3.0\n3    3.0\nName: A, dtype: float64\n\n\n\n\n\n\nDataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n\nsubset : 컬럼 라벨, 혹은 컬럼 라벨 리스트\n\n넣은 특정 컬럼만 중복값을 체크함. 기본으로는 전체 컬럼의 값이 다 같아야 제거\n\nkeep\n\nfirst : 첫 번째 등장한 것을 제외하면 다 제거\nlast : 마지막에 등장한 것을 제외하면 다 제거\nFalse : 몽땅 다 제거\n\ninplace : 원본 변경 할 건가요?\nignore_index : True 값을 넣으면, 결과값의 인덱스를 0, 1, … n-1로 라벨링함\n\n\ndf = pd.DataFrame({\n    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n    'rating': [4, 4, 3.5, 15, 5]\n})\ndf\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      0\n      Yum Yum\n      cup\n      4.0\n    \n    \n      1\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n    \n      3\n      Indomie\n      pack\n      15.0\n    \n    \n      4\n      Indomie\n      pack\n      5.0\n    \n  \n\n\n\n\n\ndf.drop_duplicates() # 모든 열의 값이 다 같으면 제거\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      0\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n    \n      3\n      Indomie\n      pack\n      15.0\n    \n    \n      4\n      Indomie\n      pack\n      5.0\n    \n  \n\n\n\n\n\ndf.drop_duplicates(subset=['brand']) # brand 컬럼 하나에서만 값이 같아도 제거\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      0\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n  \n\n\n\n\n\ndf.drop_duplicates(subset=['brand', 'style'], keep='last')\n# brand, style 모두 같으면, 마지막 값만 남김\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      1\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n    \n      4\n      Indomie\n      pack\n      5.0\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n결론부터 말하자면 데이터를 Dictionary의 리스트로 관리하다가 마지막에 Dataframe으로 만드는 것이 가장 빠르다.\n\nhttps://stackoverflow.com/questions/57000903/what-is-the-fastest-and-most-efficient-way-to-append-rows-to-a-dataframe\n\n  start_time = time.time()\n  dictinary_list = []\n  for i in range(0, end_value, 1):\n      dictionary_data = {k: random.random() for k in range(30)}\n      dictionary_list.append(dictionary_data)\n\n  df_final = pd.DataFrame.from_dict(dictionary_list)\n\n  end_time = time.time()\n  print('Execution time = %.6f seconds' % (end_time-start_time))\n\n그럼 리스트 합치는 건 뭐가 제일 빠르지?\n\nhttps://www.realpythonproject.com/day15-the-fastest-way-to-combine-lists-in-python/\nappend() is the fastest but it doesn’t combine the elements of both the lists. The + operator seems to be the ideal option. However, this has been done on a comparatively smaller dataset and results may vary when you try it on your own.\n\n\n인생은 항상 원하는대로 흘러가지 않기에, 다른 방법도 알아보자.\n\n\n\npandas.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=True)\n\ns1 = pd.Series(['a', 'b'])\ns2 = pd.Series(['c', 'd'])\npd.concat([s1, s2]) # Series 두 개 합치기\n\n0    a\n1    b\n0    c\n1    d\ndtype: object\n\n\n\npd.concat([s1, s2], ignore_index=True) # 합치면서 index 새로 만들어줌\n\n0    a\n1    b\n2    c\n3    d\ndtype: object\n\n\n\ns3 = pd.concat([s1, s2], keys=['s1', 's2']) # 최외각 레벨에 새로운 index를 만들어줌\nprint(s3)\nprint(s3['s1']) \nprint(s3['s2'][0]) # 이렇게 조회가능\n\ns1  0    a\n    1    b\ns2  0    c\n    1    d\ndtype: object\n0    a\n1    b\ndtype: object\nc\n\n\n\ns3 = pd.concat([s1, s2], keys=['s1', 's2'], names=['Series name', 'Row ID'])\n# index에 이름 붙이기\nprint(s3)\nprint(s3.index)\nprint(s3.index.names)\n\nSeries name  Row ID\ns1           0         a\n             1         b\ns2           0         c\n             1         d\ndtype: object\nMultiIndex([('s1', 0),\n            ('s1', 1),\n            ('s2', 0),\n            ('s2', 1)],\n           names=['Series name', 'Row ID'])\n['Series name', 'Row ID']\n\n\n\ndf1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\nprint(df1)\ndf2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number'])\nprint(df2)\npd.concat([df1, df2]) # Dataframe 합치기\n\n  letter  number\n0      a       1\n1      b       2\n  letter  number\n0      c       3\n1      d       4\n\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n    \n  \n  \n    \n      0\n      a\n      1\n    \n    \n      1\n      b\n      2\n    \n    \n      0\n      c\n      3\n    \n    \n      1\n      d\n      4\n    \n  \n\n\n\n\n\ndf3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n                   columns=['letter', 'number', 'animal'])\nprint(df3)\npd.concat([df1, df3], sort=False) # 한 쪽에 없는 컬럼의 값은 NaN으로 삽입됨\n\n  letter  number animal\n0      c       3    cat\n1      d       4    dog\n\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n      animal\n    \n  \n  \n    \n      0\n      a\n      1\n      NaN\n    \n    \n      1\n      b\n      2\n      NaN\n    \n    \n      0\n      c\n      3\n      cat\n    \n    \n      1\n      d\n      4\n      dog\n    \n  \n\n\n\n\n\npd.concat([df1, df3], join=\"inner\") # join=\"inner\"로 하면 양쪽에 다 있는 컬럼만 합쳐서 반환함\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n    \n  \n  \n    \n      0\n      a\n      1\n    \n    \n      1\n      b\n      2\n    \n    \n      0\n      c\n      3\n    \n    \n      1\n      d\n      4\n    \n  \n\n\n\n\n\ndf4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n                   columns=['animal', 'name'])\npd.concat([df1, df4], axis=1) # axis=1이면 컬럼을 붙임\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n      animal\n      name\n    \n  \n  \n    \n      0\n      a\n      1\n      bird\n      polly\n    \n    \n      1\n      b\n      2\n      monkey\n      george\n    \n  \n\n\n\n\n\ndf4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george'], ['dog', 'sam']],\n                   columns=['animal', 'name'])\npd.concat([df1, df4], axis=1) \n# axis=1이면 컬럼을 붙임\n# 행의 수가 다르면, 행이 적은 쪽에 NaN이 삽입된 행이 추가됨\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n      animal\n      name\n    \n  \n  \n    \n      0\n      a\n      1.0\n      bird\n      polly\n    \n    \n      1\n      b\n      2.0\n      monkey\n      george\n    \n    \n      2\n      NaN\n      NaN\n      dog\n      sam\n    \n  \n\n\n\n\n\n#collapse-output\ndf5 = pd.DataFrame([1], index=['a'])\ndf6 = pd.DataFrame([2], index=['a'])\npd.concat([df5, df6], verify_integrity=True)\n# verify_integrity=True를 하면, index가 같은 것을 허용하지 않음.\n\nValueError: Indexes have overlapping values: Index(['a'], dtype='object')\n\n\n\n\n\n\nDataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n\nright : 합칠 Dataframe\nhow : {‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’\n\nleft: use only keys from left frame, similar to a SQL left outer join; preserve key order.\nright: use only keys from right frame, similar to a SQL right outer join; preserve key order.\nouter: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\ninner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\ncross: creates the cartesian product from both frames, preserves the order of the left keys.\n\non : label or list\n\n조인할 컬럼이나 인덱스 레벨의 이름. 두 Dataframe에 무조건 있어야 한다.\n\nleft_on : label or list, or array-like\n\n왼쪽 Dataframe의 조인할 컬럼이나 인덱스 레벨의 이름.\n\nright_on : label or list, or array-like\n\n오른쪽 Dataframe의 조인할 컬럼이나 인덱스 레벨의 이름.\n\nleft_index : bool, default False\n\n왼쪽 index를 조인의 key로 사용할까요?\nMultiIndex인 경우, 상대 Dataframe의 key 수가 level의 수와 동일해야 함.\n\nright_index : bool, default False\n\n오른쪽 index를 조인의 key로 사용할까요?\nMultiIndex인 경우, 상대 Dataframe의 key 수가 level의 수와 동일해야 함.\n\nsort : bool, default False\n\n조인 결과 Dataframe에서 key를 사전 순서(lexicographically)로 배열함\nFalse인 경우, 조인 방법에 정의된 방법을 따라감\n\nsuffixes : list-like, default is (“_x”, “_y”)\n\n컬럼에 접미사를 붙인다. 왼쪽 오른쪽 구분용.\n기본적으로 왼쪽에 _x, 오른쪽에 _y가 붙는다.\n\ncopy : bool, default True\n\nFalse면, 가능하면 복사를 피한다.\n\nindicator : bool or str, default False\nvalidate : str, optional\n\nIf specified, checks if merge is of specified type.\n\n“one_to_one” or “1:1”: check if merge keys are unique in both left and right datasets.\n“one_to_many” or “1:m”: check if merge keys are unique in left dataset.\n“many_to_one” or “m:1”: check if merge keys are unique in right dataset.\n“many_to_many” or “m:m”: allowed, but does not result in checks.\n\n\n\n\ndf1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'], 'value': [1, 2, 3, 5]})\ndf2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'], 'value': [5, 6, 7, 8]})\ndisplay(df1)\ndisplay(df2)\n\n\n\n\n\n  \n    \n      \n      lkey\n      value\n    \n  \n  \n    \n      0\n      foo\n      1\n    \n    \n      1\n      bar\n      2\n    \n    \n      2\n      baz\n      3\n    \n    \n      3\n      foo\n      5\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n      \n      rkey\n      value\n    \n  \n  \n    \n      0\n      foo\n      5\n    \n    \n      1\n      bar\n      6\n    \n    \n      2\n      baz\n      7\n    \n    \n      3\n      foo\n      8\n    \n  \n\n\n\n\n\ndisplay(df1.merge(df2, left_on='lkey', right_on='rkey'))\n# 뒤에 _x, _y가 붙은 것을 확인.\ndf1.merge(df2, left_on='lkey', right_on='rkey', suffixes=('_left', '_right'))\n# _left, _right로 바꿔 보았음\n\n\n\n\n\n  \n    \n      \n      lkey\n      value_x\n      rkey\n      value_y\n    \n  \n  \n    \n      0\n      foo\n      1\n      foo\n      5\n    \n    \n      1\n      foo\n      1\n      foo\n      8\n    \n    \n      2\n      foo\n      5\n      foo\n      5\n    \n    \n      3\n      foo\n      5\n      foo\n      8\n    \n    \n      4\n      bar\n      2\n      bar\n      6\n    \n    \n      5\n      baz\n      3\n      baz\n      7\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n      \n      lkey\n      value_left\n      rkey\n      value_right\n    \n  \n  \n    \n      0\n      foo\n      1\n      foo\n      5\n    \n    \n      1\n      foo\n      1\n      foo\n      8\n    \n    \n      2\n      foo\n      5\n      foo\n      5\n    \n    \n      3\n      foo\n      5\n      foo\n      8\n    \n    \n      4\n      bar\n      2\n      bar\n      6\n    \n    \n      5\n      baz\n      3\n      baz\n      7\n    \n  \n\n\n\n\n\ndf1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\ndf2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\ndisplay(df1)\ndisplay(df2)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      foo\n      1\n    \n    \n      1\n      bar\n      2\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n      \n      a\n      c\n    \n  \n  \n    \n      0\n      foo\n      3\n    \n    \n      1\n      baz\n      4\n    \n  \n\n\n\n\n\ndf1.merge(df2, how='inner', on='a')\n# a 컬럼을 키로 잡음. 두 Dataframe에 다 a 컬럼이 있어서 가능한것\n# inner join\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      foo\n      1\n      3\n    \n  \n\n\n\n\n\ndf1.merge(df2, how='left', on='a')\n# left outer join\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      foo\n      1\n      3.0\n    \n    \n      1\n      bar\n      2\n      NaN\n    \n  \n\n\n\n\n\ndf1.merge(df2, how='left', left_on='a', right_on='a')\n# left outer join\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      foo\n      1\n      3.0\n    \n    \n      1\n      bar\n      2\n      NaN\n    \n  \n\n\n\n\n\n\n\nhttps://stackoverflow.com/questions/40860457/improve-pandas-merge-performance\nkey를 index로 사용한다.\n\nindex 검색 시에는 hash table을 이용하기 때문\nA short explanation why it is faster to merge by index instead of by a “normal” column: Indices have a hash table. Meaning you can look them up in amortized O(1). For a normal column you need O(n) in worst case, meaning merging two dfs with len n takes O(n^2) in worst case.\n\njoin을 쓴다.\nconcat을 쓴다.\n\n여기서의 결론 : key를 index로 사용한 후 join을 쓴다.\n\nimport random\ndf1 = pd.DataFrame({'uid_sample': random.sample(range(100000), 80000), 'value': random.sample(range(10000000), 80000)})\ndf2 = pd.DataFrame({'userId_sample2': random.sample(range(100000), 80000), 'value': random.sample(range(10000000), 80000)})\n# 80000명의 정보를 담고 있는 두 Dataframe이 있다고 하자.\n# uid_sample, userId_sample2를 key로 조인하고 싶다.\n\n\n%%timeit\ndf1.merge(df2, how='left', left_on='uid_sample', right_on='userId_sample2')\n\n19.4 ms ± 981 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n%%timeit\n# key로 사용하려는 컬럼을 index로 할당\n# 36%정도 빨라졌다!\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\ndf3.merge(df4, right_index=True, left_index=True)\n\n12.6 ms ± 181 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\n# key로 사용하려는 컬럼을 index로 할당\n# join 함수 사용\n# 여기서 이미 2.5배 빨라졌다\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\ndf3.join(df4, how='left', lsuffix='left', rsuffix='right')\n\n8.04 ms ± 1.21 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\n# inner, outer밖에 안 되는데 join보다 느리다.\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\npd.concat([df3, df4], axis=1, join='inner')\n\n11.5 ms ± 341 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n\n\n\nDataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n\nother : 다른 데이터프레임, 혹은 시리즈, 혹은 데이터프레임 리스트\n\n함수를 호출한 데이터프레임에 붙일 대상\n\non : 조인 키가 될 컬럼 이름, 혹은 컬럼 이름 리스트(array-like 자료형이면 됨)\nhow\n\nleft : 함수를 호출한 데이터프레임(caller)의 index를 조인 키로 사용. on에서 컬럼을 지정했을 경우, 그 컬럼을 사용\nright : other 패러미터에 할당된 객체의 index를 사용\nouter : outer join 실행 후, 사전 순으로 정렬함. 기본적으론 양쪽 다 index를 사용. on에서 지정하면 caller만 해당 컬럼 사용.\ninner : inner join 실행. caller의 순서 보존됨.\ncross : 양쪽의 곱집합 생성. left key(caller)의 순서 보존됨.\n\nlsuffix, rsuffix : join된 결과물 컬럼의 접미사 세팅.\nsort : TRUE면, join key의 사전 순서대로 정렬됨. FALSE면, how에서의 기본 처리방식을 따름.\n\n\ncaller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\nother = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 'B': ['B0', 'B1', 'B2']})\nother2 = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 'C': ['C0', 'C1', 'C2']})\n\n\ncaller_styler = caller.style.set_table_attributes(\"style='display:inline;margin:5px'\").set_caption('caller')\nother_styler = other.style.set_table_attributes(\"style='display:inline;margin:5px'\").set_caption('other')\nother2_styler = other2.style.set_table_attributes(\"style='display:inline;margin:5px'\").set_caption('other2')\ndisplay_html(caller_styler._repr_html_() + other_styler._repr_html_() + other2_styler._repr_html_(), raw=True)\n\n\ncaller                    key        A    \n                \n                        0\n                        K0\n                        A0\n            \n            \n                        1\n                        K1\n                        A1\n            \n            \n                        2\n                        K2\n                        A2\n            \n            \n                        3\n                        K3\n                        A3\n            \n            \n                        4\n                        K4\n                        A4\n            \n            \n                        5\n                        K5\n                        A5\n            \n    other                    key        B    \n                \n                        0\n                        K0\n                        B0\n            \n            \n                        1\n                        K1\n                        B1\n            \n            \n                        2\n                        K2\n                        B2\n            \n    other2                    key        C    \n                \n                        0\n                        K0\n                        C0\n            \n            \n                        1\n                        K1\n                        C1\n            \n            \n                        2\n                        K2\n                        C2\n            \n    \n\n\n\n# 이러면 index 0,1,2,3,4,5 기준으로 join됨\ncaller.join(other, lsuffix='_caller', rsuffix='_other')\n\n\n\n\n\n  \n    \n      \n      key_caller\n      A\n      key_other\n      B\n    \n  \n  \n    \n      0\n      K0\n      A0\n      K0\n      B0\n    \n    \n      1\n      K1\n      A1\n      K1\n      B1\n    \n    \n      2\n      K2\n      A2\n      K2\n      B2\n    \n    \n      3\n      K3\n      A3\n      NaN\n      NaN\n    \n    \n      4\n      K4\n      A4\n      NaN\n      NaN\n    \n    \n      5\n      K5\n      A5\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n# set_index로 조인 키로 쓰고 싶은 컬럼을 index로 만들어주는 방법이 있음\ncaller.set_index('key').join(other.set_index('key'))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n    \n      key\n      \n      \n    \n  \n  \n    \n      K0\n      A0\n      B0\n    \n    \n      K1\n      A1\n      B1\n    \n    \n      K2\n      A2\n      B2\n    \n    \n      K3\n      A3\n      NaN\n    \n    \n      K4\n      A4\n      NaN\n    \n    \n      K5\n      A5\n      NaN\n    \n  \n\n\n\n\n\n# 혹은, other만 조인 키로 쓰고 싶은 컬럼을 index로 만들어 주고,\n# on에다 조인 키로 쓰고 싶은 caller의 컬럼을 할당하는 방법이 있음\ncaller.join(other.set_index('key'), on='key')\n\n\n\n\n\n  \n    \n      \n      key\n      A\n      B\n    \n  \n  \n    \n      0\n      K0\n      A0\n      B0\n    \n    \n      1\n      K1\n      A1\n      B1\n    \n    \n      2\n      K2\n      A2\n      B2\n    \n    \n      3\n      K3\n      A3\n      NaN\n    \n    \n      4\n      K4\n      A4\n      NaN\n    \n    \n      5\n      K5\n      A5\n      NaN\n    \n  \n\n\n\n\n\n# 한 번에 여러 개의 Dataframe을 Join 할 때에는, index로 join하는 것만 지원한다.\n# 즉, on을 쓰지 못한다는 이야기이다.\ncaller.set_index('key').join([other.set_index('key'), other2.set_index('key')])\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n    \n      key\n      \n      \n      \n    \n  \n  \n    \n      K0\n      A0\n      B0\n      C0\n    \n    \n      K1\n      A1\n      B1\n      C1\n    \n    \n      K2\n      A2\n      B2\n      C2\n    \n    \n      K3\n      A3\n      NaN\n      NaN\n    \n    \n      K4\n      A4\n      NaN\n      NaN\n    \n    \n      K5\n      A5\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\n\n\n\n\nDataFrame.pivot(index=None, columns=None, values=None)\n\nindex : str or object or a list of str, optional\n\n새로운 프레임의 index로 사용할 컬럼\n\ncolumns : str of object or a list of str\n\n새로운 프레임의 컬럼으로 사용할 컬럼\n\nvalues : str, object or a list of the previous, optional\n\n새로운 프레임의 값을 계산하기 위해 사용하는 컬럼\n지정하지 않으면, 남아있는 모든 컬럼을 사용한다.\n\n\n\ndf = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n                           'two'],\n                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n                   'baz': [1, 2, 3, 4, 5, 6],\n                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\ndf\n\n\n\n\n\n  \n    \n      \n      foo\n      bar\n      baz\n      zoo\n    \n  \n  \n    \n      0\n      one\n      A\n      1\n      x\n    \n    \n      1\n      one\n      B\n      2\n      y\n    \n    \n      2\n      one\n      C\n      3\n      z\n    \n    \n      3\n      two\n      A\n      4\n      q\n    \n    \n      4\n      two\n      B\n      5\n      w\n    \n    \n      5\n      two\n      C\n      6\n      t\n    \n  \n\n\n\n\n\ndf.pivot(index='foo', columns='bar', values='baz')\n\n\n\n\n\n  \n    \n      bar\n      A\n      B\n      C\n    \n    \n      foo\n      \n      \n      \n    \n  \n  \n    \n      one\n      1\n      2\n      3\n    \n    \n      two\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf.pivot(index='foo', columns='bar')\n\n\n\n\n\n  \n    \n      \n      baz\n      zoo\n    \n    \n      bar\n      A\n      B\n      C\n      A\n      B\n      C\n    \n    \n      foo\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      one\n      1\n      2\n      3\n      x\n      y\n      z\n    \n    \n      two\n      4\n      5\n      6\n      q\n      w\n      t\n    \n  \n\n\n\n\n\ndf.pivot(index='foo', columns='bar')['baz']\n\n\n\n\n\n  \n    \n      bar\n      A\n      B\n      C\n    \n    \n      foo\n      \n      \n      \n    \n  \n  \n    \n      one\n      1\n      2\n      3\n    \n    \n      two\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf = pd.DataFrame({\n       \"lev1\": [1, 1, 1, 2, 2, 2],\n       \"lev2\": [1, 1, 2, 1, 1, 2],\n       \"lev3\": [1, 2, 1, 2, 1, 2],\n       \"lev4\": [1, 2, 3, 4, 5, 6],\n       \"values\": [0, 1, 2, 3, 4, 5]})\ndf\n\n\n\n\n\n  \n    \n      \n      lev1\n      lev2\n      lev3\n      lev4\n      values\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      0\n    \n    \n      1\n      1\n      1\n      2\n      2\n      1\n    \n    \n      2\n      1\n      2\n      1\n      3\n      2\n    \n    \n      3\n      2\n      1\n      2\n      4\n      3\n    \n    \n      4\n      2\n      1\n      1\n      5\n      4\n    \n    \n      5\n      2\n      2\n      2\n      6\n      5\n    \n  \n\n\n\n\n\ndf.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"] ,values=\"values\")\n# Multilevel Column\n# 해당하는 조건에 맞는 값이 없으면 NaN이 들어가게 됨\n\n\n\n\n\n  \n    \n      lev2\n      1\n      2\n    \n    \n      lev3\n      1\n      2\n      1\n      2\n    \n    \n      lev1\n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      0.0\n      1.0\n      2.0\n      NaN\n    \n    \n      2\n      4.0\n      3.0\n      NaN\n      5.0\n    \n  \n\n\n\n\n\ndf.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"],values=\"values\")\n# Multiindex\n\n\n\n\n\n  \n    \n      \n      lev3\n      1\n      2\n    \n    \n      lev1\n      lev2\n      \n      \n    \n  \n  \n    \n      1\n      1\n      0.0\n      1.0\n    \n    \n      2\n      2.0\n      NaN\n    \n    \n      2\n      1\n      4.0\n      3.0\n    \n    \n      2\n      NaN\n      5.0\n    \n  \n\n\n\n\n\n#collapse-output\ndf.pivot(index=[\"lev1\"], columns=[\"lev2\"],values=\"values\")\n# 인덱스, 컬럼 쌍에 중복이 발생하면 에러가 출력됨\n# ValueError: Index contains duplicate entries, cannot reshape\n\nValueError: Index contains duplicate entries, cannot reshape\n\n\n\n\n\npandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True)\n\n#hide_input\ndf = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n                         \"bar\", \"bar\", \"bar\", \"bar\"],\n                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n                         \"one\", \"one\", \"two\", \"two\"],\n                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n                         \"small\", \"large\", \"small\", \"small\",\n                         \"large\"],\n                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      foo\n      one\n      small\n      1\n      2\n    \n    \n      1\n      foo\n      one\n      large\n      2\n      4\n    \n    \n      2\n      foo\n      one\n      large\n      2\n      5\n    \n    \n      3\n      foo\n      two\n      small\n      3\n      5\n    \n    \n      4\n      foo\n      two\n      small\n      3\n      6\n    \n    \n      5\n      bar\n      one\n      large\n      4\n      6\n    \n    \n      6\n      bar\n      one\n      small\n      5\n      8\n    \n    \n      7\n      bar\n      two\n      small\n      6\n      9\n    \n    \n      8\n      bar\n      two\n      large\n      7\n      9\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'], aggfunc=np.sum)\ntable # aggfunc에 집계함수를 넣게 된다. 여기서는 총합\n\n\n\n\n\n  \n    \n      \n      C\n      large\n      small\n    \n    \n      A\n      B\n      \n      \n    \n  \n  \n    \n      bar\n      one\n      4.0\n      5.0\n    \n    \n      two\n      7.0\n      6.0\n    \n    \n      foo\n      one\n      4.0\n      1.0\n    \n    \n      two\n      NaN\n      6.0\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values='D', index=['A', 'B'],\n                    columns=['C'], aggfunc=np.sum, fill_value=0)\ntable # fill_value에 할당된 값으로 NaN을 대체하게 됨\n\n\n\n\n\n  \n    \n      \n      C\n      large\n      small\n    \n    \n      A\n      B\n      \n      \n    \n  \n  \n    \n      bar\n      one\n      4\n      5\n    \n    \n      two\n      7\n      6\n    \n    \n      foo\n      one\n      4\n      1\n    \n    \n      two\n      0\n      6\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': np.sum})\ntable # aggfunc에 Dictionary를 할당하여 값마다 집계함수를 각각 다르게 설정할 수 있다.\n\n\n\n\n\n  \n    \n      \n      \n      D\n      E\n    \n    \n      A\n      C\n      \n      \n    \n  \n  \n    \n      bar\n      large\n      5.500000\n      15\n    \n    \n      small\n      5.500000\n      17\n    \n    \n      foo\n      large\n      2.000000\n      9\n    \n    \n      small\n      2.333333\n      13\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': [min, max, np.mean]})\ntable # 한 값에 여러 개의 집계함수 할당도 가능하다.\n\n\n\n\n\n  \n    \n      \n      \n      D\n      E\n    \n    \n      \n      \n      mean\n      max\n      mean\n      min\n    \n    \n      A\n      C\n      \n      \n      \n      \n    \n  \n  \n    \n      bar\n      large\n      5.500000\n      9.0\n      7.500000\n      6.0\n    \n    \n      small\n      5.500000\n      9.0\n      8.500000\n      8.0\n    \n    \n      foo\n      large\n      2.000000\n      5.0\n      4.500000\n      4.0\n    \n    \n      small\n      2.333333\n      6.0\n      4.333333\n      2.0\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': np.mean},\n                    margins=True, margins_name=\"mean\")\ntable # Values에 적용된 집계함수를 컬럼 전체에 적용한 행을 추가한다.\n# 한 Value에 집계함수를 하나만 사용했을 때 적용 가능.\n# margins_name을 지정하지 않으면 기본적으로 행 Index 이름은 All이 된다.\n\n\n\n\n\n  \n    \n      \n      \n      D\n      E\n    \n    \n      A\n      C\n      \n      \n    \n  \n  \n    \n      bar\n      large\n      5.500000\n      7.500000\n    \n    \n      small\n      5.500000\n      8.500000\n    \n    \n      foo\n      large\n      2.000000\n      4.500000\n    \n    \n      small\n      2.333333\n      4.333333\n    \n    \n      mean\n      \n      3.666667\n      6.000000\n    \n  \n\n\n\n\n\n\n\npandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\n\nid_vars : tuple, list, or ndarray, optional\n\n식별자로 사용할 컬럼\n\nvalue_vars : tuple, list, or ndarray, optional\n\nUnpivot 할 컬럼. 지정하지 않으면, id_vars에 할당되지 않은 모든 컬럼을 사용\n\n\n\ndf = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n                   'B': {0: 1, 1: 3, 2: 5},\n                   'C': {0: 2, 1: 4, 2: 6}})\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      a\n      1\n      2\n    \n    \n      1\n      b\n      3\n      4\n    \n    \n      2\n      c\n      5\n      6\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B'])\n\n\n\n\n\n  \n    \n      \n      A\n      variable\n      value\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'])\n\n\n\n\n\n  \n    \n      \n      A\n      variable\n      value\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n    \n      3\n      a\n      C\n      2\n    \n    \n      4\n      b\n      C\n      4\n    \n    \n      5\n      c\n      C\n      6\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B'],\n        var_name='myVarname', value_name='myValname')\n# 이름은 커스터마이징 가능\n\n\n\n\n\n  \n    \n      \n      A\n      myVarname\n      myValname\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n# 원본 index 유지\n\n\n\n\n\n  \n    \n      \n      A\n      variable\n      value\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n    \n      0\n      a\n      C\n      2\n    \n    \n      1\n      b\n      C\n      4\n    \n    \n      2\n      c\n      C\n      6\n    \n  \n\n\n\n\n\n\n\n\n\n\n\ndf = pd.DataFrame({'float': [1.0],\n                   'int': [1],\n                   'datetime': [pd.Timestamp('20180310')],\n                   'string': ['foo']})\ndf.dtypes\n# 더 이상의 설명은 필요 없다!\n\nfloat              float64\nint                  int64\ndatetime    datetime64[ns]\nstring              object\ndtype: object\n\n\n\n\n\nDataFrame.select_dtypes(include=None, exclude=None)\n\nTo select all numeric types, use np.number or ‘number’\nTo select strings you must use the object dtype, but note that this will return all object dtype columns See the numpy dtype hierarchy\nTo select datetimes, use np.datetime64, ‘datetime’ or ‘datetime64’\nTo select timedeltas, use np.timedelta64, ‘timedelta’ or ‘timedelta64’\nTo select Pandas categorical dtypes, use ‘category’\nTo select Pandas datetimetz dtypes, use ‘datetimetz’ (new in 0.20.0) or ‘datetime64[ns, tz]’\n\n\ndf = pd.DataFrame({'a': [1, 2] * 3,\n                   'b': [True, False] * 3,\n                   'c': [1.0, 2.0] * 3})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      True\n      1.0\n    \n    \n      1\n      2\n      False\n      2.0\n    \n    \n      2\n      1\n      True\n      1.0\n    \n    \n      3\n      2\n      False\n      2.0\n    \n    \n      4\n      1\n      True\n      1.0\n    \n    \n      5\n      2\n      False\n      2.0\n    \n  \n\n\n\n\n\ndf.select_dtypes(include='bool')\n\n\n\n\n\n  \n    \n      \n      b\n    \n  \n  \n    \n      0\n      True\n    \n    \n      1\n      False\n    \n    \n      2\n      True\n    \n    \n      3\n      False\n    \n    \n      4\n      True\n    \n    \n      5\n      False\n    \n  \n\n\n\n\n\ndf.select_dtypes(include=['float64'])\n\n\n\n\n\n  \n    \n      \n      c\n    \n  \n  \n    \n      0\n      1.0\n    \n    \n      1\n      2.0\n    \n    \n      2\n      1.0\n    \n    \n      3\n      2.0\n    \n    \n      4\n      1.0\n    \n    \n      5\n      2.0\n    \n  \n\n\n\n\n\ndf.select_dtypes(exclude=['int64'])\n\n\n\n\n\n  \n    \n      \n      b\n      c\n    \n  \n  \n    \n      0\n      True\n      1.0\n    \n    \n      1\n      False\n      2.0\n    \n    \n      2\n      True\n      1.0\n    \n    \n      3\n      False\n      2.0\n    \n    \n      4\n      True\n      1.0\n    \n    \n      5\n      False\n      2.0\n    \n  \n\n\n\n\n\n\n\nDataFrame.astype(dtype, copy=True, errors='raise')\n\ncopy : False를 하면, 복사를 하는 게 아니고 원본에 연결되므로 변경사항이 원본에까지 전파됨\nerrors : ignore로 세팅하면, 에러 발생 시 원본을 반환하고 끝냄\n\n\nd = {'col1': [1, 2], 'col2': [3, 4]}\ndf = pd.DataFrame(data=d)\ndf.dtypes\n\ncol1    int64\ncol2    int64\ndtype: object\n\n\n\ndf.astype({'col1': 'int32'}).dtypes\n# 잘 변경됐습니다~\n\ncol1    int32\ncol2    int64\ndtype: object\n\n\n\n\n\n\n\n\n\nstring_quest = pd.read_excel(r\"C:\\Users\\limyj0708\\Documents\\data\\string\\string_quest.xlsx\",\n                             header=6, usecols=\"H,I\", sheet_name = \"string_quest\", engine=\"openpyxl\")\n\n\nheader : 몇 번째 row를 header로 할까?\nusercols : 어떤 열을 가져올까?\nsheet_name : 어떤 시트를 가져올까?\nengine : openpyxl을 사용하여야 xlsx 파일의 불러오기가 가능\n\n\n\n\n\n\n\ndataframe-image 패키지를 이용 시, linux에서 crontab으로 실행할 경우 복잡한 권한 문제에 직면하게 됨\ndataframe-image 패키지도 matplotlib 기반이므로, 그냥 matplotlib를 사용\n\n\nimport six\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n\n# matplotlib에서 한글이 안 나오는 문제 해결\nNANUM = fm.FontProperties(fname=r'C:\\Users\\limyj0708\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumBarunGothic.ttf')\nNANUM_bold = fm.FontProperties(fname=r'C:\\Users\\limyj0708\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumBarunGothicBold.ttf')\n\n# centos라면 폰트 경로는 아래와 같음\n ## /usr/share/fonts/NanumFont/NanumBarunGothic.ttf\n ## /usr/share/fonts/NanumFont/NanumGothicBold.ttf\n\ndef render_mpl_table(data, col_width=3.0, row_height=0.625, font_size_header=16, font_size=14,\n                     header_color='#C2DED1', row_colors=['#f1f1f2', 'w'], edge_color='black',\n                     bbox=[0, 0, 1, 1], header_columns=0,\n                     ax=None, align_head='center', align_cell='center', **kwargs):\n    \"\"\"\n    align_head, align_cell : [ 'center' | 'right' | 'left' ] \n    \"\"\"\n    \n    if ax is None:\n        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n        fig, ax = plt.subplots(figsize=size)\n        ax.axis('off')\n\n    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n    mpl_table.auto_set_font_size(False)\n\n    for k, cell in  six.iteritems(mpl_table._cells):\n        cell.set_edgecolor(edge_color)\n        if k[0] == 0 or k[1] < header_columns:\n            cell.set_facecolor(header_color)\n            cell.set_text_props(color='black', fontproperties = NANUM_bold, fontsize=font_size_header, ha=align_head)\n        else:\n            cell.set_facecolor(row_colors[k[0]%len(row_colors)])\n            cell.set_text_props(fontproperties = NANUM, fontsize=font_size, ha=align_cell)\n    return ax\n\nimage = render_mpl_table(caller, col_width=2.0, align_head='left')\nimage\nimage.figure.savefig(\"caller.png\") # 이미지 저장\n# crontab으로 돌릴 것이라면 이미지 저장 경로도 절대경로로 지정"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html#dataframe-생성",
    "href": "posts/2021-11-05-pandas_cheatsheet.html#dataframe-생성",
    "title": "limyj_code_archive",
    "section": "1. Dataframe 생성",
    "text": "1. Dataframe 생성\n\n1-1. Dictionary에서 Dataframe 생성\n\ndata = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\npd.DataFrame.from_dict(data)\n# key가 컬럼, value로 들어간 리스트가 컬럼의 row 하나하나가 된다.\n\n\n\n\n\n  \n    \n      \n      col_1\n      col_2\n    \n  \n  \n    \n      0\n      3\n      a\n    \n    \n      1\n      2\n      b\n    \n    \n      2\n      1\n      c\n    \n    \n      3\n      0\n      d\n    \n  \n\n\n\n\n\ndict_list = [\n    { \"id\" : 1001001, \"address\" : \"AABCC\"}\n    ,{ \"id\" : 2101001, \"address\" : \"BBBDD\"}\n    ,{ \"id\" : 3201001, \"address\" : \"백두산\"}\n    ,{ \"id\" : 4301001, \"address\" : \"한라산\"}\n    ,{ \"id\" : 5401001, \"address\" : \"몰디브\"}\n] # 같은 key들을 가진 딕셔너리들이 담긴 리스트\npd.DataFrame.from_dict(dict_list) # 이렇게 넣어도, key들이 컬럼이 되어 데이터프레임이 만들어진다.\n# 실무적으로는 이 형태를 더 많이 쓰게 된다.\n\n\n\n\n\n  \n    \n      \n      id\n      address\n    \n  \n  \n    \n      0\n      1001001\n      AABCC\n    \n    \n      1\n      2101001\n      BBBDD\n    \n    \n      2\n      3201001\n      백두산\n    \n    \n      3\n      4301001\n      한라산\n    \n    \n      4\n      5401001\n      몰디브\n    \n  \n\n\n\n\n\n\n1-2. Column만 존재하는 빈 Dataframe을 만들고, 내용 채워 넣기\n\ndf = pd.DataFrame(columns=['A','B','BB','C','D'])\n# 컬럼들이 될 리스트를 columns parameter에 argument로 넘김\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n  \n\n\n\n\n\ndf['A'] = [1,3,1]\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      3\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      NaN\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ndf['B'] = [4,4,6]\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[((df['A'] == 1) & (df['B'] == 4)), 'C'] = 444\ndf\n# 컬럼 값 조건을 걸고 값을 변경\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      444\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[(df['B'] == 4), 'C'] = 0\ndf\n# 컬럼 값 조건을 걸고 값을 변경 2\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n  \n\n\n\n\n\nsample_list = [1,2,3,4,5]\n# 해당 데이터프레임 가장 아래에 리스트를 row로 넣음\ndf.loc[len(df)] = sample_list\n# 이 방식은 좀 느린 편이며, 데이터프레임에 행을 추가해야 한다면\n# 자료를 dictionary로 관리하다가 모든 데이터 추가가 다 끝나고 데이터프레임으로 변환하는 것이 빠름\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html#indexing-값-변경-추가",
    "href": "posts/2021-11-05-pandas_cheatsheet.html#indexing-값-변경-추가",
    "title": "limyj_code_archive",
    "section": "2. Indexing, 값 변경 & 추가",
    "text": "2. Indexing, 값 변경 & 추가\n\n2-1. loc : 라벨 인덱싱\n\nprint(type(df.loc[0]))\ndf.loc[0]\n# loc의 첫 번째 인자는 '행 라벨' 이다.\n# 그래서 0을 넣으면, index가 0인 행을 series로 반환하고 있다.\n\n<class 'pandas.core.series.Series'>\n\n\nA       1\nB       4\nBB    NaN\nC       0\nD     NaN\nName: 0, dtype: object\n\n\n\nprint(type(df.loc[0, 'A']))\ndf.loc[0, 'A']\n# 두 번째 인자는 컬럼명이다.\n\n<class 'numpy.int64'>\n\n\n1\n\n\n\ndf.loc[[0,1,2,3], ['A','B']]\n# 이런 식으로 접근하면, 다중 컬럼과 행을 데이터프레임으로 가져올 수 있다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      4\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      1\n      6\n    \n    \n      3\n      1\n      2\n    \n  \n\n\n\n\n\ndf.loc[df.index[0:3], ['A','B']]\n# df.index로도 접근 가능\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      4\n    \n    \n      1\n      3\n      4\n    \n    \n      2\n      1\n      6\n    \n  \n\n\n\n\n\ndf.loc[df['B'] == 4]\n# row에 값 조건을 걸 수도 있다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[df['B'] == 4, df.columns.str.contains('B')]\n# 컬럼 이름에도 조건을 걸 수 있다. 위의 경우, 컬럼 이름에 B를 포함하는 컬럼만 가져옴.\n\n\n\n\n\n  \n    \n      \n      B\n      BB\n    \n  \n  \n    \n      0\n      4\n      NaN\n    \n    \n      1\n      4\n      NaN\n    \n  \n\n\n\n\n\ndf.loc[:,df.columns.str.contains('B')]\n# 행 조건 자리에 :를 넣으면, 행에 대해서는 전체를 다 가져오라는 뜻이다.\n\n\n\n\n\n  \n    \n      \n      B\n      BB\n    \n  \n  \n    \n      0\n      4\n      NaN\n    \n    \n      1\n      4\n      NaN\n    \n    \n      2\n      6\n      NaN\n    \n    \n      3\n      2\n      3\n    \n  \n\n\n\n\n\nprint(df.columns) # 컬럼명을 가져옴\nprint(df.columns.str)\nprint(df.columns.str.contains('B')) # boolean indexing이 가능한 형태가 된다.\nprint(type(df.columns.str.contains('B'))) # 결과물은 false와 true가 들어간 ndarray\nprint(df.columns.str.startswith('A')) # 이렇게 하면 A로 시작하는 컬럼을 가져올 수 있음\n# 결론은, 다른 외부 함수를 사용해서 어쩄든 boolean 타입 값이 담긴 리스트를 만들면, loc에 넣어서 boolean indexing이 가능하다는 것.\n\nIndex(['A', 'B', 'BB', 'C', 'D'], dtype='object')\n<pandas.core.strings.StringMethods object at 0x000001E1FEC0B250>\n[False  True  True False False]\n<class 'numpy.ndarray'>\n[ True False False False False]\n\n\n\ndf.loc[:,'new'] = 3\ndf\n# loc으로도 기존에 없던 새 컬럼을 추가할 수 있음\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n    \n  \n\n\n\n\n\ndf.loc[4] = [1] * len(df.columns)\ndf.loc[99] = [1] * len(df.columns)\ndf.loc['cool'] = [22] * len(df.columns)\n# dataframe에 행을 추가함. index가 늘어난다.\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22\n    \n  \n\n\n\n\n\n\n2-2. iloc : 위치 인덱싱\n\ndf.iloc[0:2,0:4]\n# 기본적 동작은 loc과 동일하나, 받는 인자가 라벨이 아니고 '위치'다.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n    \n    \n      1\n      3\n      4\n      NaN\n      0\n    \n  \n\n\n\n\n\ndf.iloc[4:7,0:4]\n# 위치를 받기 때문에, index는 99여도 5번째 줄로 인식됨\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n    \n  \n  \n    \n      4\n      1\n      1\n      1\n      1\n    \n    \n      99\n      1\n      1\n      1\n      1\n    \n    \n      cool\n      22\n      22\n      22\n      22\n    \n  \n\n\n\n\n\ndf.iloc[7] = [2] * len(df.columns)\n# IndexError: iloc cannot enlarge its target object\n# 위치를 인자로 받기 때문에, 새로운 컬럼, 행을 만든다거나 하는 행위는 불가능하다.\n\nIndexError: iloc cannot enlarge its target object\n\n\n\n\n2-3. at : 스칼라값 접근\n\ndf.at[1,'A']\n# 한 번에 1개의 스칼라값에만 접근 가능\n# 여러 개의 값에 접근하려고 범위를 지정하면, 에러를 출력한다.\n# 단일 값에 접근하는 목적이라면 loc보다 훨씬 빠름\n\n3\n\n\n\ndf.at[1,'A'] = 100\ndf\n# 값을 딱 하나만 바꾸고 싶다! 라고 하면 at을 활용해보자.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      3\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22\n    \n  \n\n\n\n\n\ndf.at[99, 'new']\n# 그 이외에는 label base인 것이 loc과 똑같음\n\n1\n\n\n\n\n2-4. iat : iloc의 스칼라 버전\n\ndf.iat[4,2]\n# iloc의 스칼라 버전.\n# 이외의 동작은 at과 같다.\n\n1\n\n\n\ndf.iat[df.index.get_loc('cool'),df.columns.get_loc('new')]\n# get_loc을 쓰면, 해당 인덱스와 컬럼의 위치를 반환받을 수 있음.\n# 그럼 인덱스와 컬럼의 이름으로도 iat, iloc을 이용 가능\n\n22\n\n\n\n\n2-5 map : Series의 원소 하나하나에 함수 적용\n\nmap함수는 DataFrame 타입이 아니라, 반드시 Series 타입에서만 사용해야 한다.\nSeries를 한마디로 정의하면 딱 이거다.\n\n값(value) + 인덱스(index) = 시리즈 클래스(Series)\n\nSeries는 NumPy에서 제공하는 1차원 배열과 비슷하지만 각 데이터의 의미를 표시하는 인덱스(index)를 붙일 수 있다. 하지만 데이터 자체는 그냥 값(value)의 1차원 배열이다.\nmap함수는 Series의 이러한 값 하나하나에 접근하면서 해당 함수를 수행한다.\n\n\nimport math as m # sqrt 함수 사용을 위해 부름\n# http://www.leejungmin.org/post/2018/04/21/pandas_apply_and_map/\ndf[\"map_b\"] = df[\"B\"].map(lambda x : m.sqrt(x)) \n# B컬럼의 값 하나하나에 sqrt 함수를 적용한 결과를 map_b 컬럼으로 추가\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n      map_b\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      3\n      2.000000\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      3\n      2.000000\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      3\n      2.449490\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      3\n      1.414214\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22\n      4.690416\n    \n  \n\n\n\n\n\n\n2-6. apply : 커스텀 함수에 복수 개의 컬럼이 필요하다면\n\n커스텀 함수를 사용하기 위해 DataFrame에서 복수 개의 컬럼이 필요하다면, apply 함수를 사용해야 한다.\n\n\nimport math as m # sqrt 함수 사용을 위해 부름\n# 두 컬럼의 제곱근의 값을 각각 곱하는 함수\ndef sqrt_multi(x,y):\n    return m.sqrt(x) * m.sqrt(y)\n\n\ndf.loc[:,'new'] = df.apply(lambda x : sqrt_multi(x['A'], x['B']), axis=1) # axis=1 이면 각 열의 원소에 대해 연산 수행\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n      map_b\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\ndf[\"apply_bb_d\"] = df.apply(lambda x : sqrt_multi(x['BB'], x['B']), axis=1) # axis=1 이면 각 열의 원소에 대해 연산 수행\ndf # NaN과의 연산은 NaN이 됨을 참고하자.\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      BB\n      C\n      D\n      new\n      map_b\n      apply_bb_d\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      99\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      cool\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\n\n2-7. index, columns로 index와 컬럼명 직접 지정\n\nprint(df.columns)\nprint(type(df.columns))\nprint(df.index)\nprint(type(df.index))\nprint(df.columns[2]) # 위치값으로 개별 요소에 접근 가능\nprint(df.index[6])\n\nIndex(['A', 'B', 'BB', 'C', 'D', 'new', 'map_b', 'apply_bb_d'], dtype='object')\n<class 'pandas.core.indexes.base.Index'>\nIndex([0, 1, 2, 3, 4, 99, 'cool'], dtype='object')\n<class 'pandas.core.indexes.base.Index'>\nBB\ncool\n\n\n\ndf.columns = ['가', '나', '다', '라', '마', '바', '사', '아'] \n# df.columns에 직접 컬럼명 리스트를 할당하여 컬럼명 변경 가능\n# 기존 컬럼 수와 같은 길이의 리스트를 넣지 않으면 오류가 발생함\nprint(df.columns)\nprint(type(df.columns))\n\nIndex(['가', '나', '다', '라', '마', '바', '사', '아'], dtype='object')\n<class 'pandas.core.indexes.base.Index'>\n\n\n\ndf.index = [1,2,3,4,5,6,7] \n# df.columns에 직접 컬럼명 리스트를 할당하여 컬럼명 변경 가능\nprint(df.index)\nprint(type(df.index))\n\nInt64Index([1, 2, 3, 4, 5, 6, 7], dtype='int64')\n<class 'pandas.core.indexes.numeric.Int64Index'>\n\n\n\n\n2-8. set_index로 index 설정\nDataFrame.set_index(keys, drop=True, append=False, inplace=False) - keys에는 index로 할당하고자 하는 열의 레이블을 입력한다. - multi-index를 하고 싶으면, [‘가’, ‘나’] 이렇게 열 레이블 배열을 입력한다. - drop : index로 할당한 열을 삭제할까요? - append : 기존에 존재하던 index를 삭제할까요? - inplace : 원본 데이터프레임을 변경할까요?\n\ndf\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index('가') # 기본값\n\n\n\n\n\n  \n    \n      \n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      가\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index('가', drop=False) # index로 선택된 열 삭제 안 함\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      가\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      100\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      1\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      1\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      1\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      22\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index('가', append=True) # 기존 index 삭제 안 함\n\n\n\n\n\n  \n    \n      \n      \n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      \n      가\n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.set_index(['가','나']) # 동시에 여러 열을 index로 설정하기\n\n\n\n\n\n  \n    \n      \n      \n      다\n      라\n      마\n      바\n      사\n      아\n    \n    \n      가\n      나\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\n\n2-9. reset_index로 index 초기화\nDataFrame.reset_index(drop=False, inplace=False) - 기존에 있던 index 대신에, 0부터 시작하여 1씩 늘어나는 정수 index를 추가한다. - drop : 기존에 index였던 열을 삭제할까요? - inplace : 원본 데이터프레임을 변경할까요?\n\ndf.reset_index()\n\n\n\n\n\n  \n    \n      \n      index\n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      0\n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      1\n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      2\n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      3\n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      4\n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      5\n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.reset_index(drop=True)\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      0\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      1\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      2\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      3\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      4\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html#값-삭제-대체",
    "href": "posts/2021-11-05-pandas_cheatsheet.html#값-삭제-대체",
    "title": "limyj_code_archive",
    "section": "3. 값 삭제, 대체",
    "text": "3. 값 삭제, 대체\n\n특정 조건의 값을 삭제하고 싶은 경우에는, 해당 조건의 반대 조건을 걸어서 반환 결과를 사용하는 식으로 처리한다.\n\n\n3-1. drop : 원하는 행, 열 지우기\nDataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise') - 특정 레이블의 행이나 열을 제거한다. - labels : 제거할 index, 레이블 하나 혹은 리스트 (list-like) - axis : 0이면 행, 1이면 컬럼 대상 - index : labels, axis=0 대신 사용가능 - columns : labels, axis=1 대신 사용가능 - level : MultiIndex일 경우, 어떤 레벨을 제거할 것인지 - inplace : 원본 변경 할 건가요? - errors : ’ignore’로 세팅하면, 에러 출력 안 하고 존재하는 레이블만 제거한다.\n\ndf\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.drop(labels=['가','아'], axis=1)\n\n\n\n\n\n  \n    \n      \n      나\n      다\n      라\n      마\n      바\n      사\n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n    \n    \n      2\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n    \n    \n      3\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n    \n    \n      4\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\ndf.drop(labels=[1,7], axis=0)\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n  \n\n\n\n\n\ndf.drop(columns=['가','아'])\n# df.drop(labels=['가','아'], axis=1)와 같은 결과\n\n\n\n\n\n  \n    \n      \n      나\n      다\n      라\n      마\n      바\n      사\n    \n  \n  \n    \n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n    \n    \n      2\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n    \n    \n      3\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n    \n    \n      4\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\n\n3-2. Na 대응\n\n3-2-1. isna : NaN인지 각 값에 대해 확인\n\nNaN인지 각 값에 대해 확인하여 boolean으로 표현\nisnull() 도 완전히 같은 기능을 한다.\n왜 같은 기능을 하는 함수가 두 개나 있는지는 아래 링크를 참조\n\nhttps://datascience.stackexchange.com/questions/37878/difference-between-isna-and-isnull-in-pandas > This is because pandas’ DataFrames are based on R’s DataFrames. In R na and null are two separate things. Read this post for more information. However, in python, pandas is built on top of numpy, which has neither na nor null values. Instead numpy has NaN values (which stands for “Not a Number”). Consequently, pandas also uses NaN values.\n\n\n\ndf.isna()\n# 특정 컬럼, 행에 대해서도 사용 가능\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n      True\n    \n    \n      2\n      False\n      False\n      True\n      False\n      True\n      False\n      False\n      True\n    \n    \n      3\n      False\n      False\n      True\n      True\n      True\n      False\n      False\n      True\n    \n    \n      4\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      5\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      6\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n    \n      7\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n      False\n    \n  \n\n\n\n\n\n\n3-2-2. dropna : NA 드랍\nDataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False) - axis - 0 혹은 ‘index’ : missing value가 있는 행을 드랍 - 1 혹은 ‘columns’ : missing value가 있는 열을 드랍 - how - any : missing value가 하나라도 있으면 드랍 - all : 전체 값이 다 missing value여야 드랍 - thresh : 문턱값. 정수를 입력 시, 정상값이 해당 정수 갯수만큼은 있어야 제거 안 함 - subset : list-like 오브젝트를 넣으면, 해당 index나 컬럼에서만 missing value 체크 - inplace : 원본 변경 할 건가요?\n\ndf\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      3\n      1\n      6\n      NaN\n      NaN\n      NaN\n      2.449490\n      2.449490\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.dropna() # 기본적으로 행 드랍\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.dropna(axis=1) # 열 드랍\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      바\n      사\n    \n  \n  \n    \n      1\n      1\n      4\n      2.000000\n      2.000000\n    \n    \n      2\n      100\n      4\n      20.000000\n      2.000000\n    \n    \n      3\n      1\n      6\n      2.449490\n      2.449490\n    \n    \n      4\n      1\n      2\n      1.414214\n      1.414214\n    \n    \n      5\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      6\n      1\n      1\n      1.000000\n      1.000000\n    \n    \n      7\n      22\n      22\n      22.000000\n      4.690416\n    \n  \n\n\n\n\n\ndf.dropna(thresh=5) # index 3인 행은 정상값이 4개였음\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\ndf.dropna(axis=0, subset=['라']) # '라'열만 검사해서 NaN이 있는 행을 제거함\n\n\n\n\n\n  \n    \n      \n      가\n      나\n      다\n      라\n      마\n      바\n      사\n      아\n    \n  \n  \n    \n      1\n      1\n      4\n      NaN\n      0\n      NaN\n      2.000000\n      2.000000\n      NaN\n    \n    \n      2\n      100\n      4\n      NaN\n      0\n      NaN\n      20.000000\n      2.000000\n      NaN\n    \n    \n      4\n      1\n      2\n      3\n      4\n      5\n      1.414214\n      1.414214\n      2.44949\n    \n    \n      5\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      6\n      1\n      1\n      1\n      1\n      1\n      1.000000\n      1.000000\n      1.00000\n    \n    \n      7\n      22\n      22\n      22\n      22\n      22\n      22.000000\n      4.690416\n      22.00000\n    \n  \n\n\n\n\n\n\n3-2-3. fillna : NaN 데이터 대체하기\nDataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None) - value : NaN을 무엇으로 채울 것인가? - scalar : 0, 1 따위의 값을 넣음 - dict : {“A”: 0, “B”: 1, “C”: 2, “D”: 3} - 컬럼 A의 NaN은 0으로, 컬럼 B의 NaN은 1로, 컬럼 C의 NaN은 2로, 컬럼 D의 NaN은 3으로 대체 - dataframe : 대체 대상 dataframe와 같은 크기의 dataframe을 준비한 후, value에 dataframe을 넣으면 NaN 값만 넣은 dataframe의 값으로 대체된다. 컬럼명이나 인덱스는 원본 dataframe의 것이 유지된다. - method : 어떤 방법으로 채울까? (value와 같이 사용할 수 없음) - backfill, bfill : NaN의 다음 값으로 NaN 채우기. - ffill, pad : NaN의 직전 값으로 NaN 채우기. - axis - 0 혹은 ‘index’ - 1 혹은 ‘columns’ - inplace : 원본 변경 할 건가요? - limit : 위에서부터 NaN 몇 개만 바꿀래? 기본값 None이면 모든 NaN을 바꾸는 것.\n\ndf = pd.DataFrame([[np.nan, 2, np.nan, 0],\n                   [3, 4, np.nan, 1],\n                   [np.nan, np.nan, np.nan, 5],\n                   [np.nan, 3, np.nan, 4]],\n                  columns=list(\"ABCD\"))\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      NaN\n      2.0\n      NaN\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n      5\n    \n    \n      3\n      NaN\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\ndf.fillna(value=0) # 0으로 NaN 채우기\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      0.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      0.0\n      1\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      5\n    \n    \n      3\n      0.0\n      3.0\n      0.0\n      4\n    \n  \n\n\n\n\n\ndf.fillna(method='ffill') # NaN의 직전 값으로 NaN 채우기. 'pad'를 써도 마찬가지\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      NaN\n      2.0\n      NaN\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      3.0\n      4.0\n      NaN\n      5\n    \n    \n      3\n      3.0\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\ndf.fillna(method='bfill') # NaN의 다음 값으로 NaN 채우기. 'backfill'을 써도 마찬가지\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      3.0\n      2.0\n      NaN\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      NaN\n      3.0\n      NaN\n      5\n    \n    \n      3\n      NaN\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\nvalues = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\ndf.fillna(value=values) # values에 dictionary를 넣어서 컬럼마다 NaN을 다른 값으로 대체\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      2.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      2.0\n      1\n    \n    \n      2\n      0.0\n      1.0\n      2.0\n      5\n    \n    \n      3\n      0.0\n      3.0\n      2.0\n      4\n    \n  \n\n\n\n\n\ndf.fillna(value=values, limit=1) # limit=1이어서, 최초의 NaN 하나만 대체\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      2.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      NaN\n      1\n    \n    \n      2\n      NaN\n      1.0\n      NaN\n      5\n    \n    \n      3\n      NaN\n      3.0\n      NaN\n      4\n    \n  \n\n\n\n\n\ndf2 = pd.DataFrame(np.zeros((4, 4)), columns=list(\"ABCE\"))\ndf2 # 4 by 4 영행렬을 만들어 보자\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      E\n    \n  \n  \n    \n      0\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      1\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      0.0\n      0.0\n      0.0\n      0.0\n    \n  \n\n\n\n\n\ndf.fillna(df2) #원본 df의 컬럼이 유지됨\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      0.0\n      0\n    \n    \n      1\n      3.0\n      4.0\n      0.0\n      1\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      5\n    \n    \n      3\n      0.0\n      3.0\n      0.0\n      4\n    \n  \n\n\n\n\n\ndf.loc[:,'A'].fillna(df.loc[:,'A'].mean()) # A열의 NaN 값을 A열의 평균으로 채움\n\n0    3.0\n1    3.0\n2    3.0\n3    3.0\nName: A, dtype: float64\n\n\n\n\n\n3-3. drop_duplicates : 중복값 제거\nDataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)\n\nsubset : 컬럼 라벨, 혹은 컬럼 라벨 리스트\n\n넣은 특정 컬럼만 중복값을 체크함. 기본으로는 전체 컬럼의 값이 다 같아야 제거\n\nkeep\n\nfirst : 첫 번째 등장한 것을 제외하면 다 제거\nlast : 마지막에 등장한 것을 제외하면 다 제거\nFalse : 몽땅 다 제거\n\ninplace : 원본 변경 할 건가요?\nignore_index : True 값을 넣으면, 결과값의 인덱스를 0, 1, … n-1로 라벨링함\n\n\ndf = pd.DataFrame({\n    'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\n    'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\n    'rating': [4, 4, 3.5, 15, 5]\n})\ndf\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      0\n      Yum Yum\n      cup\n      4.0\n    \n    \n      1\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n    \n      3\n      Indomie\n      pack\n      15.0\n    \n    \n      4\n      Indomie\n      pack\n      5.0\n    \n  \n\n\n\n\n\ndf.drop_duplicates() # 모든 열의 값이 다 같으면 제거\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      0\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n    \n      3\n      Indomie\n      pack\n      15.0\n    \n    \n      4\n      Indomie\n      pack\n      5.0\n    \n  \n\n\n\n\n\ndf.drop_duplicates(subset=['brand']) # brand 컬럼 하나에서만 값이 같아도 제거\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      0\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n  \n\n\n\n\n\ndf.drop_duplicates(subset=['brand', 'style'], keep='last')\n# brand, style 모두 같으면, 마지막 값만 남김\n\n\n\n\n\n  \n    \n      \n      brand\n      style\n      rating\n    \n  \n  \n    \n      1\n      Yum Yum\n      cup\n      4.0\n    \n    \n      2\n      Indomie\n      cup\n      3.5\n    \n    \n      4\n      Indomie\n      pack\n      5.0"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html#dataframe-결합",
    "href": "posts/2021-11-05-pandas_cheatsheet.html#dataframe-결합",
    "title": "limyj_code_archive",
    "section": "4. Dataframe 결합",
    "text": "4. Dataframe 결합\n\n4-1. 위아래로 붙이는 단순 결합의 경우, 어떤 방식이 가장 빠른가?\n\n결론부터 말하자면 데이터를 Dictionary의 리스트로 관리하다가 마지막에 Dataframe으로 만드는 것이 가장 빠르다.\n\nhttps://stackoverflow.com/questions/57000903/what-is-the-fastest-and-most-efficient-way-to-append-rows-to-a-dataframe\n\n  start_time = time.time()\n  dictinary_list = []\n  for i in range(0, end_value, 1):\n      dictionary_data = {k: random.random() for k in range(30)}\n      dictionary_list.append(dictionary_data)\n\n  df_final = pd.DataFrame.from_dict(dictionary_list)\n\n  end_time = time.time()\n  print('Execution time = %.6f seconds' % (end_time-start_time))\n\n\n그럼 리스트 합치는 건 뭐가 제일 빠르지?\n\nhttps://www.realpythonproject.com/day15-the-fastest-way-to-combine-lists-in-python/ > append() is the fastest but it doesn’t combine the elements of both the lists. The + operator seems to be the ideal option. However, this has been done on a comparatively smaller dataset and results may vary when you try it on your own.\n\n\n인생은 항상 원하는대로 흘러가지 않기에, 다른 방법도 알아보자.\n\n\n4-1-1. concat\npandas.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=True)\n\ns1 = pd.Series(['a', 'b'])\ns2 = pd.Series(['c', 'd'])\npd.concat([s1, s2]) # Series 두 개 합치기\n\n0    a\n1    b\n0    c\n1    d\ndtype: object\n\n\n\npd.concat([s1, s2], ignore_index=True) # 합치면서 index 새로 만들어줌\n\n0    a\n1    b\n2    c\n3    d\ndtype: object\n\n\n\ns3 = pd.concat([s1, s2], keys=['s1', 's2']) # 최외각 레벨에 새로운 index를 만들어줌\nprint(s3)\nprint(s3['s1']) \nprint(s3['s2'][0]) # 이렇게 조회가능\n\ns1  0    a\n    1    b\ns2  0    c\n    1    d\ndtype: object\n0    a\n1    b\ndtype: object\nc\n\n\n\ns3 = pd.concat([s1, s2], keys=['s1', 's2'], names=['Series name', 'Row ID'])\n# index에 이름 붙이기\nprint(s3)\nprint(s3.index)\nprint(s3.index.names)\n\nSeries name  Row ID\ns1           0         a\n             1         b\ns2           0         c\n             1         d\ndtype: object\nMultiIndex([('s1', 0),\n            ('s1', 1),\n            ('s2', 0),\n            ('s2', 1)],\n           names=['Series name', 'Row ID'])\n['Series name', 'Row ID']\n\n\n\ndf1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\nprint(df1)\ndf2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number'])\nprint(df2)\npd.concat([df1, df2]) # Dataframe 합치기\n\n  letter  number\n0      a       1\n1      b       2\n  letter  number\n0      c       3\n1      d       4\n\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n    \n  \n  \n    \n      0\n      a\n      1\n    \n    \n      1\n      b\n      2\n    \n    \n      0\n      c\n      3\n    \n    \n      1\n      d\n      4\n    \n  \n\n\n\n\n\ndf3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n                   columns=['letter', 'number', 'animal'])\nprint(df3)\npd.concat([df1, df3], sort=False) # 한 쪽에 없는 컬럼의 값은 NaN으로 삽입됨\n\n  letter  number animal\n0      c       3    cat\n1      d       4    dog\n\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n      animal\n    \n  \n  \n    \n      0\n      a\n      1\n      NaN\n    \n    \n      1\n      b\n      2\n      NaN\n    \n    \n      0\n      c\n      3\n      cat\n    \n    \n      1\n      d\n      4\n      dog\n    \n  \n\n\n\n\n\npd.concat([df1, df3], join=\"inner\") # join=\"inner\"로 하면 양쪽에 다 있는 컬럼만 합쳐서 반환함\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n    \n  \n  \n    \n      0\n      a\n      1\n    \n    \n      1\n      b\n      2\n    \n    \n      0\n      c\n      3\n    \n    \n      1\n      d\n      4\n    \n  \n\n\n\n\n\ndf4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n                   columns=['animal', 'name'])\npd.concat([df1, df4], axis=1) # axis=1이면 컬럼을 붙임\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n      animal\n      name\n    \n  \n  \n    \n      0\n      a\n      1\n      bird\n      polly\n    \n    \n      1\n      b\n      2\n      monkey\n      george\n    \n  \n\n\n\n\n\ndf4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george'], ['dog', 'sam']],\n                   columns=['animal', 'name'])\npd.concat([df1, df4], axis=1) \n# axis=1이면 컬럼을 붙임\n# 행의 수가 다르면, 행이 적은 쪽에 NaN이 삽입된 행이 추가됨\n\n\n\n\n\n  \n    \n      \n      letter\n      number\n      animal\n      name\n    \n  \n  \n    \n      0\n      a\n      1.0\n      bird\n      polly\n    \n    \n      1\n      b\n      2.0\n      monkey\n      george\n    \n    \n      2\n      NaN\n      NaN\n      dog\n      sam\n    \n  \n\n\n\n\n\n#collapse-output\ndf5 = pd.DataFrame([1], index=['a'])\ndf6 = pd.DataFrame([2], index=['a'])\npd.concat([df5, df6], verify_integrity=True)\n# verify_integrity=True를 하면, index가 같은 것을 허용하지 않음.\n\nValueError: Indexes have overlapping values: Index(['a'], dtype='object')\n\n\n\n\n\n4-2. Merge : Database의 Join처럼 Dataframe 합치기\nDataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None)\n\nright : 합칠 Dataframe\nhow : {‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}, default ‘inner’\n\nleft: use only keys from left frame, similar to a SQL left outer join; preserve key order.\nright: use only keys from right frame, similar to a SQL right outer join; preserve key order.\nouter: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\ninner: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\ncross: creates the cartesian product from both frames, preserves the order of the left keys.\n\non : label or list\n\n조인할 컬럼이나 인덱스 레벨의 이름. 두 Dataframe에 무조건 있어야 한다.\n\nleft_on : label or list, or array-like\n\n왼쪽 Dataframe의 조인할 컬럼이나 인덱스 레벨의 이름.\n\nright_on : label or list, or array-like\n\n오른쪽 Dataframe의 조인할 컬럼이나 인덱스 레벨의 이름.\n\nleft_index : bool, default False\n\n왼쪽 index를 조인의 key로 사용할까요?\nMultiIndex인 경우, 상대 Dataframe의 key 수가 level의 수와 동일해야 함.\n\nright_index : bool, default False\n\n오른쪽 index를 조인의 key로 사용할까요?\nMultiIndex인 경우, 상대 Dataframe의 key 수가 level의 수와 동일해야 함.\n\nsort : bool, default False\n\n조인 결과 Dataframe에서 key를 사전 순서(lexicographically)로 배열함\nFalse인 경우, 조인 방법에 정의된 방법을 따라감\n\nsuffixes : list-like, default is (“_x”, “_y”)\n\n컬럼에 접미사를 붙인다. 왼쪽 오른쪽 구분용.\n기본적으로 왼쪽에 _x, 오른쪽에 _y가 붙는다.\n\ncopy : bool, default True\n\nFalse면, 가능하면 복사를 피한다.\n\nindicator : bool or str, default False\nvalidate : str, optional\n\nIf specified, checks if merge is of specified type.\n\n“one_to_one” or “1:1”: check if merge keys are unique in both left and right datasets.\n“one_to_many” or “1:m”: check if merge keys are unique in left dataset.\n“many_to_one” or “m:1”: check if merge keys are unique in right dataset.\n“many_to_many” or “m:m”: allowed, but does not result in checks.\n\n\n\n\ndf1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'], 'value': [1, 2, 3, 5]})\ndf2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'], 'value': [5, 6, 7, 8]})\ndisplay(df1)\ndisplay(df2)\n\n\n\n\n\n  \n    \n      \n      lkey\n      value\n    \n  \n  \n    \n      0\n      foo\n      1\n    \n    \n      1\n      bar\n      2\n    \n    \n      2\n      baz\n      3\n    \n    \n      3\n      foo\n      5\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n      \n      rkey\n      value\n    \n  \n  \n    \n      0\n      foo\n      5\n    \n    \n      1\n      bar\n      6\n    \n    \n      2\n      baz\n      7\n    \n    \n      3\n      foo\n      8\n    \n  \n\n\n\n\n\ndisplay(df1.merge(df2, left_on='lkey', right_on='rkey'))\n# 뒤에 _x, _y가 붙은 것을 확인.\ndf1.merge(df2, left_on='lkey', right_on='rkey', suffixes=('_left', '_right'))\n# _left, _right로 바꿔 보았음\n\n\n\n\n\n  \n    \n      \n      lkey\n      value_x\n      rkey\n      value_y\n    \n  \n  \n    \n      0\n      foo\n      1\n      foo\n      5\n    \n    \n      1\n      foo\n      1\n      foo\n      8\n    \n    \n      2\n      foo\n      5\n      foo\n      5\n    \n    \n      3\n      foo\n      5\n      foo\n      8\n    \n    \n      4\n      bar\n      2\n      bar\n      6\n    \n    \n      5\n      baz\n      3\n      baz\n      7\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n      \n      lkey\n      value_left\n      rkey\n      value_right\n    \n  \n  \n    \n      0\n      foo\n      1\n      foo\n      5\n    \n    \n      1\n      foo\n      1\n      foo\n      8\n    \n    \n      2\n      foo\n      5\n      foo\n      5\n    \n    \n      3\n      foo\n      5\n      foo\n      8\n    \n    \n      4\n      bar\n      2\n      bar\n      6\n    \n    \n      5\n      baz\n      3\n      baz\n      7\n    \n  \n\n\n\n\n\ndf1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\ndf2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\ndisplay(df1)\ndisplay(df2)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n    \n  \n  \n    \n      0\n      foo\n      1\n    \n    \n      1\n      bar\n      2\n    \n  \n\n\n\n\n\n\n\n\n  \n    \n      \n      a\n      c\n    \n  \n  \n    \n      0\n      foo\n      3\n    \n    \n      1\n      baz\n      4\n    \n  \n\n\n\n\n\ndf1.merge(df2, how='inner', on='a')\n# a 컬럼을 키로 잡음. 두 Dataframe에 다 a 컬럼이 있어서 가능한것\n# inner join\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      foo\n      1\n      3\n    \n  \n\n\n\n\n\ndf1.merge(df2, how='left', on='a')\n# left outer join\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      foo\n      1\n      3.0\n    \n    \n      1\n      bar\n      2\n      NaN\n    \n  \n\n\n\n\n\ndf1.merge(df2, how='left', left_on='a', right_on='a')\n# left outer join\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      foo\n      1\n      3.0\n    \n    \n      1\n      bar\n      2\n      NaN\n    \n  \n\n\n\n\n\n4-2-1. Dataframe Join의 속도를 향상시키기 위해서는?\n\nhttps://stackoverflow.com/questions/40860457/improve-pandas-merge-performance\nkey를 index로 사용한다.\n\nindex 검색 시에는 hash table을 이용하기 때문 > A short explanation why it is faster to merge by index instead of by a “normal” column: Indices have a hash table. Meaning you can look them up in amortized O(1). For a normal column you need O(n) in worst case, meaning merging two dfs with len n takes O(n^2) in worst case.\n\njoin을 쓴다.\nconcat을 쓴다.\n\n여기서의 결론 : key를 index로 사용한 후 join을 쓴다.\n\nimport random\ndf1 = pd.DataFrame({'uid_sample': random.sample(range(100000), 80000), 'value': random.sample(range(10000000), 80000)})\ndf2 = pd.DataFrame({'userId_sample2': random.sample(range(100000), 80000), 'value': random.sample(range(10000000), 80000)})\n# 80000명의 정보를 담고 있는 두 Dataframe이 있다고 하자.\n# uid_sample, userId_sample2를 key로 조인하고 싶다.\n\n\n%%timeit\ndf1.merge(df2, how='left', left_on='uid_sample', right_on='userId_sample2')\n\n19.4 ms ± 981 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n%%timeit\n# key로 사용하려는 컬럼을 index로 할당\n# 36%정도 빨라졌다!\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\ndf3.merge(df4, right_index=True, left_index=True)\n\n12.6 ms ± 181 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\n# key로 사용하려는 컬럼을 index로 할당\n# join 함수 사용\n# 여기서 이미 2.5배 빨라졌다\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\ndf3.join(df4, how='left', lsuffix='left', rsuffix='right')\n\n8.04 ms ± 1.21 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n%%timeit\n# inner, outer밖에 안 되는데 join보다 느리다.\ndf3 = df1.set_index('uid_sample')\ndf4 = df2.set_index('userId_sample2')\npd.concat([df3, df4], axis=1, join='inner')\n\n11.5 ms ± 341 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n\n\n\n\n\n4-3. Join : Merge보다 빠르다\nDataFrame.join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False) - other : 다른 데이터프레임, 혹은 시리즈, 혹은 데이터프레임 리스트 - 함수를 호출한 데이터프레임에 붙일 대상 - on : 조인 키가 될 컬럼 이름, 혹은 컬럼 이름 리스트(array-like 자료형이면 됨) - how - left : 함수를 호출한 데이터프레임(caller)의 index를 조인 키로 사용. on에서 컬럼을 지정했을 경우, 그 컬럼을 사용 - right : other 패러미터에 할당된 객체의 index를 사용 - outer : outer join 실행 후, 사전 순으로 정렬함. 기본적으론 양쪽 다 index를 사용. on에서 지정하면 caller만 해당 컬럼 사용. - inner : inner join 실행. caller의 순서 보존됨. - cross : 양쪽의 곱집합 생성. left key(caller)의 순서 보존됨. - lsuffix, rsuffix : join된 결과물 컬럼의 접미사 세팅. - sort : TRUE면, join key의 사전 순서대로 정렬됨. FALSE면, how에서의 기본 처리방식을 따름.\n\ncaller = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\nother = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 'B': ['B0', 'B1', 'B2']})\nother2 = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 'C': ['C0', 'C1', 'C2']})\n\n\ncaller_styler = caller.style.set_table_attributes(\"style='display:inline;margin:5px'\").set_caption('caller')\nother_styler = other.style.set_table_attributes(\"style='display:inline;margin:5px'\").set_caption('other')\nother2_styler = other2.style.set_table_attributes(\"style='display:inline;margin:5px'\").set_caption('other2')\ndisplay_html(caller_styler._repr_html_() + other_styler._repr_html_() + other2_styler._repr_html_(), raw=True)\n\n\ncaller                    key        A    \n                \n                        0\n                        K0\n                        A0\n            \n            \n                        1\n                        K1\n                        A1\n            \n            \n                        2\n                        K2\n                        A2\n            \n            \n                        3\n                        K3\n                        A3\n            \n            \n                        4\n                        K4\n                        A4\n            \n            \n                        5\n                        K5\n                        A5\n            \n    other                    key        B    \n                \n                        0\n                        K0\n                        B0\n            \n            \n                        1\n                        K1\n                        B1\n            \n            \n                        2\n                        K2\n                        B2\n            \n    other2                    key        C    \n                \n                        0\n                        K0\n                        C0\n            \n            \n                        1\n                        K1\n                        C1\n            \n            \n                        2\n                        K2\n                        C2\n            \n    \n\n\n\n# 이러면 index 0,1,2,3,4,5 기준으로 join됨\ncaller.join(other, lsuffix='_caller', rsuffix='_other')\n\n\n\n\n\n  \n    \n      \n      key_caller\n      A\n      key_other\n      B\n    \n  \n  \n    \n      0\n      K0\n      A0\n      K0\n      B0\n    \n    \n      1\n      K1\n      A1\n      K1\n      B1\n    \n    \n      2\n      K2\n      A2\n      K2\n      B2\n    \n    \n      3\n      K3\n      A3\n      NaN\n      NaN\n    \n    \n      4\n      K4\n      A4\n      NaN\n      NaN\n    \n    \n      5\n      K5\n      A5\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n# set_index로 조인 키로 쓰고 싶은 컬럼을 index로 만들어주는 방법이 있음\ncaller.set_index('key').join(other.set_index('key'))\n\n\n\n\n\n  \n    \n      \n      A\n      B\n    \n    \n      key\n      \n      \n    \n  \n  \n    \n      K0\n      A0\n      B0\n    \n    \n      K1\n      A1\n      B1\n    \n    \n      K2\n      A2\n      B2\n    \n    \n      K3\n      A3\n      NaN\n    \n    \n      K4\n      A4\n      NaN\n    \n    \n      K5\n      A5\n      NaN\n    \n  \n\n\n\n\n\n# 혹은, other만 조인 키로 쓰고 싶은 컬럼을 index로 만들어 주고,\n# on에다 조인 키로 쓰고 싶은 caller의 컬럼을 할당하는 방법이 있음\ncaller.join(other.set_index('key'), on='key')\n\n\n\n\n\n  \n    \n      \n      key\n      A\n      B\n    \n  \n  \n    \n      0\n      K0\n      A0\n      B0\n    \n    \n      1\n      K1\n      A1\n      B1\n    \n    \n      2\n      K2\n      A2\n      B2\n    \n    \n      3\n      K3\n      A3\n      NaN\n    \n    \n      4\n      K4\n      A4\n      NaN\n    \n    \n      5\n      K5\n      A5\n      NaN\n    \n  \n\n\n\n\n\n# 한 번에 여러 개의 Dataframe을 Join 할 때에는, index로 join하는 것만 지원한다.\n# 즉, on을 쓰지 못한다는 이야기이다.\ncaller.set_index('key').join([other.set_index('key'), other2.set_index('key')])\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n    \n      key\n      \n      \n      \n    \n  \n  \n    \n      K0\n      A0\n      B0\n      C0\n    \n    \n      K1\n      A1\n      B1\n      C1\n    \n    \n      K2\n      A2\n      B2\n      C2\n    \n    \n      K3\n      A3\n      NaN\n      NaN\n    \n    \n      K4\n      A4\n      NaN\n      NaN\n    \n    \n      K5\n      A5\n      NaN\n      NaN"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html#데이터-재구조화",
    "href": "posts/2021-11-05-pandas_cheatsheet.html#데이터-재구조화",
    "title": "limyj_code_archive",
    "section": "5. 데이터 재구조화",
    "text": "5. 데이터 재구조화\n\n5.1 Pivot : 엑셀에서 보던 그것\nDataFrame.pivot(index=None, columns=None, values=None) - index : str or object or a list of str, optional - 새로운 프레임의 index로 사용할 컬럼 - columns : str of object or a list of str - 새로운 프레임의 컬럼으로 사용할 컬럼 - values : str, object or a list of the previous, optional - 새로운 프레임의 값을 계산하기 위해 사용하는 컬럼 - 지정하지 않으면, 남아있는 모든 컬럼을 사용한다.\n\ndf = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n                           'two'],\n                   'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n                   'baz': [1, 2, 3, 4, 5, 6],\n                   'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\ndf\n\n\n\n\n\n  \n    \n      \n      foo\n      bar\n      baz\n      zoo\n    \n  \n  \n    \n      0\n      one\n      A\n      1\n      x\n    \n    \n      1\n      one\n      B\n      2\n      y\n    \n    \n      2\n      one\n      C\n      3\n      z\n    \n    \n      3\n      two\n      A\n      4\n      q\n    \n    \n      4\n      two\n      B\n      5\n      w\n    \n    \n      5\n      two\n      C\n      6\n      t\n    \n  \n\n\n\n\n\ndf.pivot(index='foo', columns='bar', values='baz')\n\n\n\n\n\n  \n    \n      bar\n      A\n      B\n      C\n    \n    \n      foo\n      \n      \n      \n    \n  \n  \n    \n      one\n      1\n      2\n      3\n    \n    \n      two\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf.pivot(index='foo', columns='bar')\n\n\n\n\n\n  \n    \n      \n      baz\n      zoo\n    \n    \n      bar\n      A\n      B\n      C\n      A\n      B\n      C\n    \n    \n      foo\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      one\n      1\n      2\n      3\n      x\n      y\n      z\n    \n    \n      two\n      4\n      5\n      6\n      q\n      w\n      t\n    \n  \n\n\n\n\n\ndf.pivot(index='foo', columns='bar')['baz']\n\n\n\n\n\n  \n    \n      bar\n      A\n      B\n      C\n    \n    \n      foo\n      \n      \n      \n    \n  \n  \n    \n      one\n      1\n      2\n      3\n    \n    \n      two\n      4\n      5\n      6\n    \n  \n\n\n\n\n\ndf = pd.DataFrame({\n       \"lev1\": [1, 1, 1, 2, 2, 2],\n       \"lev2\": [1, 1, 2, 1, 1, 2],\n       \"lev3\": [1, 2, 1, 2, 1, 2],\n       \"lev4\": [1, 2, 3, 4, 5, 6],\n       \"values\": [0, 1, 2, 3, 4, 5]})\ndf\n\n\n\n\n\n  \n    \n      \n      lev1\n      lev2\n      lev3\n      lev4\n      values\n    \n  \n  \n    \n      0\n      1\n      1\n      1\n      1\n      0\n    \n    \n      1\n      1\n      1\n      2\n      2\n      1\n    \n    \n      2\n      1\n      2\n      1\n      3\n      2\n    \n    \n      3\n      2\n      1\n      2\n      4\n      3\n    \n    \n      4\n      2\n      1\n      1\n      5\n      4\n    \n    \n      5\n      2\n      2\n      2\n      6\n      5\n    \n  \n\n\n\n\n\ndf.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"] ,values=\"values\")\n# Multilevel Column\n# 해당하는 조건에 맞는 값이 없으면 NaN이 들어가게 됨\n\n\n\n\n\n  \n    \n      lev2\n      1\n      2\n    \n    \n      lev3\n      1\n      2\n      1\n      2\n    \n    \n      lev1\n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      0.0\n      1.0\n      2.0\n      NaN\n    \n    \n      2\n      4.0\n      3.0\n      NaN\n      5.0\n    \n  \n\n\n\n\n\ndf.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"],values=\"values\")\n# Multiindex\n\n\n\n\n\n  \n    \n      \n      lev3\n      1\n      2\n    \n    \n      lev1\n      lev2\n      \n      \n    \n  \n  \n    \n      1\n      1\n      0.0\n      1.0\n    \n    \n      2\n      2.0\n      NaN\n    \n    \n      2\n      1\n      4.0\n      3.0\n    \n    \n      2\n      NaN\n      5.0\n    \n  \n\n\n\n\n\n#collapse-output\ndf.pivot(index=[\"lev1\"], columns=[\"lev2\"],values=\"values\")\n# 인덱스, 컬럼 쌍에 중복이 발생하면 에러가 출력됨\n# ValueError: Index contains duplicate entries, cannot reshape\n\nValueError: Index contains duplicate entries, cannot reshape\n\n\n\n\n5.2 Pivot_table : Pivot의 확장 버전\npandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False, sort=True)\n\n#hide_input\ndf = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n                         \"bar\", \"bar\", \"bar\", \"bar\"],\n                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n                         \"one\", \"one\", \"two\", \"two\"],\n                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n                         \"small\", \"large\", \"small\", \"small\",\n                         \"large\"],\n                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      E\n    \n  \n  \n    \n      0\n      foo\n      one\n      small\n      1\n      2\n    \n    \n      1\n      foo\n      one\n      large\n      2\n      4\n    \n    \n      2\n      foo\n      one\n      large\n      2\n      5\n    \n    \n      3\n      foo\n      two\n      small\n      3\n      5\n    \n    \n      4\n      foo\n      two\n      small\n      3\n      6\n    \n    \n      5\n      bar\n      one\n      large\n      4\n      6\n    \n    \n      6\n      bar\n      one\n      small\n      5\n      8\n    \n    \n      7\n      bar\n      two\n      small\n      6\n      9\n    \n    \n      8\n      bar\n      two\n      large\n      7\n      9\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'], aggfunc=np.sum)\ntable # aggfunc에 집계함수를 넣게 된다. 여기서는 총합\n\n\n\n\n\n  \n    \n      \n      C\n      large\n      small\n    \n    \n      A\n      B\n      \n      \n    \n  \n  \n    \n      bar\n      one\n      4.0\n      5.0\n    \n    \n      two\n      7.0\n      6.0\n    \n    \n      foo\n      one\n      4.0\n      1.0\n    \n    \n      two\n      NaN\n      6.0\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values='D', index=['A', 'B'],\n                    columns=['C'], aggfunc=np.sum, fill_value=0)\ntable # fill_value에 할당된 값으로 NaN을 대체하게 됨\n\n\n\n\n\n  \n    \n      \n      C\n      large\n      small\n    \n    \n      A\n      B\n      \n      \n    \n  \n  \n    \n      bar\n      one\n      4\n      5\n    \n    \n      two\n      7\n      6\n    \n    \n      foo\n      one\n      4\n      1\n    \n    \n      two\n      0\n      6\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': np.sum})\ntable # aggfunc에 Dictionary를 할당하여 값마다 집계함수를 각각 다르게 설정할 수 있다.\n\n\n\n\n\n  \n    \n      \n      \n      D\n      E\n    \n    \n      A\n      C\n      \n      \n    \n  \n  \n    \n      bar\n      large\n      5.500000\n      15\n    \n    \n      small\n      5.500000\n      17\n    \n    \n      foo\n      large\n      2.000000\n      9\n    \n    \n      small\n      2.333333\n      13\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': [min, max, np.mean]})\ntable # 한 값에 여러 개의 집계함수 할당도 가능하다.\n\n\n\n\n\n  \n    \n      \n      \n      D\n      E\n    \n    \n      \n      \n      mean\n      max\n      mean\n      min\n    \n    \n      A\n      C\n      \n      \n      \n      \n    \n  \n  \n    \n      bar\n      large\n      5.500000\n      9.0\n      7.500000\n      6.0\n    \n    \n      small\n      5.500000\n      9.0\n      8.500000\n      8.0\n    \n    \n      foo\n      large\n      2.000000\n      5.0\n      4.500000\n      4.0\n    \n    \n      small\n      2.333333\n      6.0\n      4.333333\n      2.0\n    \n  \n\n\n\n\n\ntable = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n                    aggfunc={'D': np.mean,\n                             'E': np.mean},\n                    margins=True, margins_name=\"mean\")\ntable # Values에 적용된 집계함수를 컬럼 전체에 적용한 행을 추가한다.\n# 한 Value에 집계함수를 하나만 사용했을 때 적용 가능.\n# margins_name을 지정하지 않으면 기본적으로 행 Index 이름은 All이 된다.\n\n\n\n\n\n  \n    \n      \n      \n      D\n      E\n    \n    \n      A\n      C\n      \n      \n    \n  \n  \n    \n      bar\n      large\n      5.500000\n      7.500000\n    \n    \n      small\n      5.500000\n      8.500000\n    \n    \n      foo\n      large\n      2.000000\n      4.500000\n    \n    \n      small\n      2.333333\n      4.333333\n    \n    \n      mean\n      \n      3.666667\n      6.000000\n    \n  \n\n\n\n\n\n\n5.3 melt : Unpivot 하기\npandas.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\n\nid_vars : tuple, list, or ndarray, optional\n\n식별자로 사용할 컬럼\n\nvalue_vars : tuple, list, or ndarray, optional\n\nUnpivot 할 컬럼. 지정하지 않으면, id_vars에 할당되지 않은 모든 컬럼을 사용\n\n\n\ndf = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},\n                   'B': {0: 1, 1: 3, 2: 5},\n                   'C': {0: 2, 1: 4, 2: 6}})\ndf\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n    \n  \n  \n    \n      0\n      a\n      1\n      2\n    \n    \n      1\n      b\n      3\n      4\n    \n    \n      2\n      c\n      5\n      6\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B'])\n\n\n\n\n\n  \n    \n      \n      A\n      variable\n      value\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'])\n\n\n\n\n\n  \n    \n      \n      A\n      variable\n      value\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n    \n      3\n      a\n      C\n      2\n    \n    \n      4\n      b\n      C\n      4\n    \n    \n      5\n      c\n      C\n      6\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B'],\n        var_name='myVarname', value_name='myValname')\n# 이름은 커스터마이징 가능\n\n\n\n\n\n  \n    \n      \n      A\n      myVarname\n      myValname\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n  \n\n\n\n\n\npd.melt(df, id_vars=['A'], value_vars=['B', 'C'], ignore_index=False)\n# 원본 index 유지\n\n\n\n\n\n  \n    \n      \n      A\n      variable\n      value\n    \n  \n  \n    \n      0\n      a\n      B\n      1\n    \n    \n      1\n      b\n      B\n      3\n    \n    \n      2\n      c\n      B\n      5\n    \n    \n      0\n      a\n      C\n      2\n    \n    \n      1\n      b\n      C\n      4\n    \n    \n      2\n      c\n      C\n      6"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html#데이터-타입",
    "href": "posts/2021-11-05-pandas_cheatsheet.html#데이터-타입",
    "title": "limyj_code_archive",
    "section": "6. 데이터 타입",
    "text": "6. 데이터 타입\n\n6-1. dtypes : 컬럼들의 type 출력\n\ndf = pd.DataFrame({'float': [1.0],\n                   'int': [1],\n                   'datetime': [pd.Timestamp('20180310')],\n                   'string': ['foo']})\ndf.dtypes\n# 더 이상의 설명은 필요 없다!\n\nfloat              float64\nint                  int64\ndatetime    datetime64[ns]\nstring              object\ndtype: object\n\n\n\n\n6-2. select_dtypes : 특정 타입의 컬럼을 선택, 혹은 배제\nDataFrame.select_dtypes(include=None, exclude=None)\n\nTo select all numeric types, use np.number or ‘number’\nTo select strings you must use the object dtype, but note that this will return all object dtype columns See the numpy dtype hierarchy\nTo select datetimes, use np.datetime64, ‘datetime’ or ‘datetime64’\nTo select timedeltas, use np.timedelta64, ‘timedelta’ or ‘timedelta64’\nTo select Pandas categorical dtypes, use ‘category’\nTo select Pandas datetimetz dtypes, use ‘datetimetz’ (new in 0.20.0) or ‘datetime64[ns, tz]’\n\n\ndf = pd.DataFrame({'a': [1, 2] * 3,\n                   'b': [True, False] * 3,\n                   'c': [1.0, 2.0] * 3})\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      True\n      1.0\n    \n    \n      1\n      2\n      False\n      2.0\n    \n    \n      2\n      1\n      True\n      1.0\n    \n    \n      3\n      2\n      False\n      2.0\n    \n    \n      4\n      1\n      True\n      1.0\n    \n    \n      5\n      2\n      False\n      2.0\n    \n  \n\n\n\n\n\ndf.select_dtypes(include='bool')\n\n\n\n\n\n  \n    \n      \n      b\n    \n  \n  \n    \n      0\n      True\n    \n    \n      1\n      False\n    \n    \n      2\n      True\n    \n    \n      3\n      False\n    \n    \n      4\n      True\n    \n    \n      5\n      False\n    \n  \n\n\n\n\n\ndf.select_dtypes(include=['float64'])\n\n\n\n\n\n  \n    \n      \n      c\n    \n  \n  \n    \n      0\n      1.0\n    \n    \n      1\n      2.0\n    \n    \n      2\n      1.0\n    \n    \n      3\n      2.0\n    \n    \n      4\n      1.0\n    \n    \n      5\n      2.0\n    \n  \n\n\n\n\n\ndf.select_dtypes(exclude=['int64'])\n\n\n\n\n\n  \n    \n      \n      b\n      c\n    \n  \n  \n    \n      0\n      True\n      1.0\n    \n    \n      1\n      False\n      2.0\n    \n    \n      2\n      True\n      1.0\n    \n    \n      3\n      False\n      2.0\n    \n    \n      4\n      True\n      1.0\n    \n    \n      5\n      False\n      2.0\n    \n  \n\n\n\n\n\n\n6-3. astype : 타입 변경. Bigquery에 df 업로드 시 반드시 사용\nDataFrame.astype(dtype, copy=True, errors='raise')\n\ncopy : False를 하면, 복사를 하는 게 아니고 원본에 연결되므로 변경사항이 원본에까지 전파됨\nerrors : ignore로 세팅하면, 에러 발생 시 원본을 반환하고 끝냄\n\n\nd = {'col1': [1, 2], 'col2': [3, 4]}\ndf = pd.DataFrame(data=d)\ndf.dtypes\n\ncol1    int64\ncol2    int64\ndtype: object\n\n\n\ndf.astype({'col1': 'int32'}).dtypes\n# 잘 변경됐습니다~\n\ncol1    int32\ncol2    int64\ndtype: object"
  },
  {
    "objectID": "posts/2021-11-05-pandas_cheatsheet.html#파일-입출력",
    "href": "posts/2021-11-05-pandas_cheatsheet.html#파일-입출력",
    "title": "limyj_code_archive",
    "section": "7. 파일 입출력",
    "text": "7. 파일 입출력\n\n7-1. read_excel : xlsx 파일을 읽기 위해서는?\n\nstring_quest = pd.read_excel(r\"C:\\Users\\limyj0708\\Documents\\data\\string\\string_quest.xlsx\",\n                             header=6, usecols=\"H,I\", sheet_name = \"string_quest\", engine=\"openpyxl\")\n\n\nheader : 몇 번째 row를 header로 할까?\nusercols : 어떤 열을 가져올까?\nsheet_name : 어떤 시트를 가져올까?\nengine : openpyxl을 사용하여야 xlsx 파일의 불러오기가 가능\n\n\n\n7-2. Dataframe을 이미지로 추출\n\nmatplotlib를 이용\n\ndataframe-image 패키지를 이용 시, linux에서 crontab으로 실행할 경우 복잡한 권한 문제에 직면하게 됨\ndataframe-image 패키지도 matplotlib 기반이므로, 그냥 matplotlib를 사용\n\n\nimport six\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as fm\n\n# matplotlib에서 한글이 안 나오는 문제 해결\nNANUM = fm.FontProperties(fname=r'C:\\Users\\limyj0708\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumBarunGothic.ttf')\nNANUM_bold = fm.FontProperties(fname=r'C:\\Users\\limyj0708\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumBarunGothicBold.ttf')\n\n# centos라면 폰트 경로는 아래와 같음\n ## /usr/share/fonts/NanumFont/NanumBarunGothic.ttf\n ## /usr/share/fonts/NanumFont/NanumGothicBold.ttf\n\ndef render_mpl_table(data, col_width=3.0, row_height=0.625, font_size_header=16, font_size=14,\n                     header_color='#C2DED1', row_colors=['#f1f1f2', 'w'], edge_color='black',\n                     bbox=[0, 0, 1, 1], header_columns=0,\n                     ax=None, align_head='center', align_cell='center', **kwargs):\n    \"\"\"\n    align_head, align_cell : [ 'center' | 'right' | 'left' ] \n    \"\"\"\n    \n    if ax is None:\n        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n        fig, ax = plt.subplots(figsize=size)\n        ax.axis('off')\n\n    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, **kwargs)\n    mpl_table.auto_set_font_size(False)\n\n    for k, cell in  six.iteritems(mpl_table._cells):\n        cell.set_edgecolor(edge_color)\n        if k[0] == 0 or k[1] < header_columns:\n            cell.set_facecolor(header_color)\n            cell.set_text_props(color='black', fontproperties = NANUM_bold, fontsize=font_size_header, ha=align_head)\n        else:\n            cell.set_facecolor(row_colors[k[0]%len(row_colors)])\n            cell.set_text_props(fontproperties = NANUM, fontsize=font_size, ha=align_cell)\n    return ax\n\nimage = render_mpl_table(caller, col_width=2.0, align_head='left')\nimage\nimage.figure.savefig(\"caller.png\") # 이미지 저장\n# crontab으로 돌릴 것이라면 이미지 저장 경로도 절대경로로 지정"
  }
]